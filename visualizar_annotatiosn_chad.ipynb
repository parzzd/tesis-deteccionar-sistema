{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d65c6d62",
   "metadata": {},
   "source": [
    "ANALISIS DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c850de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos normales (0): 278\n",
      "Archivos anómalos (1): 134\n",
      "Total archivos: 412\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "labels_dir = r\"CHAD\\CHAD_Meta\\anomaly_labels\"\n",
    "\n",
    "count_normal = 0\n",
    "count_anomalous = 0\n",
    "\n",
    "for filename in os.listdir(labels_dir):\n",
    "    if filename.endswith(\".npy\"):\n",
    "        label = filename.split(\"_\")[-1].split(\".\")[0]\n",
    "        if label == \"1\":\n",
    "            count_anomalous += 1\n",
    "        elif label == \"0\":\n",
    "            count_normal += 1\n",
    "\n",
    "print(f\"Archivos normales (0): {count_normal}\")\n",
    "print(f\"Archivos anómalos (1): {count_anomalous}\")\n",
    "print(f\"Total archivos: {count_normal + count_anomalous}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505eac24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando archivo: 1_071_1.npy\n",
      "Tipo: <class 'numpy.ndarray'>\n",
      "Shape: (599,)\n",
      "Valores únicos: [0. 1.]\n",
      "Primeros 20 valores: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "example_file = Path(r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\CHAD\\CHAD_Meta\\anomaly_labels\\1_071_1.npy\")\n",
    "\n",
    "\n",
    "print(f\"Analizando archivo: {example_file.name}\")\n",
    "\n",
    "data = np.load(example_file, allow_pickle=True)\n",
    "\n",
    "print(\"Tipo:\", type(data))\n",
    "print(\"Shape:\", data.shape)\n",
    "\n",
    "if isinstance(data, np.ndarray):\n",
    "    print(\"Valores únicos:\", np.unique(data))\n",
    "    print(\"Primeros 20 valores:\", data[:])\n",
    "\n",
    "else:\n",
    "    print(\"Contenido:\")\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa281e1",
   "metadata": {},
   "source": [
    "ANALIZAR KEYPOINTS POR VIDEO DE PRUEBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7eccc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s-pose.pt to 'yolov8s-pose.pt': 100% ━━━━━━━━━━━━ 22.4MB 26.8MB/s 0.8s.8s<0.3ss\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "VIDEO_IN   = r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\DATASETS_COMBINADOS\\anomalia\\V_21.mp4\"\n",
    "VIDEO_OUT  = r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\video_keypoints.mp4\"\n",
    "MODEL_PATH = \"yolo11m-pose.pt\"   # correcto\n",
    "IMGSZ      = 960\n",
    "CONF_TH    = 0.25\n",
    "IOU_TH     = 0.50\n",
    "DRAW_CONF  = 0.20                             \n",
    "\n",
    "SKELETON = [\n",
    "    (0,1),(0,2),(1,3),(2,4),\n",
    "    (5,6),(5,7),(7,9),(6,8),(8,10),\n",
    "    (5,11),(6,12),(11,12),(11,13),(13,15),(12,14),(14,16)\n",
    "]\n",
    "\n",
    "COLORS = [(255,0,0),(0,255,0),(0,0,255),(255,255,0),(255,0,255),(0,255,255)]\n",
    "\n",
    "# =============== DIBUJO ===============\n",
    "def draw_poses(frame, kps_xy, kps_conf, skeleton=SKELETON, conf_th=DRAW_CONF):\n",
    "    h, w = frame.shape[:2]\n",
    "    for i in range(kps_xy.shape[0]):  # por persona\n",
    "        color = COLORS[i % len(COLORS)]\n",
    "        pts = kps_xy[i].astype(int)            # (17,2)\n",
    "        conf = kps_conf[i] if kps_conf is not None else np.ones(17)\n",
    "\n",
    "        # puntos\n",
    "        for (x, y), c in zip(pts, conf):\n",
    "            if c >= conf_th and 0 <= x < w and 0 <= y < h:\n",
    "                cv2.circle(frame, (int(x), int(y)), 2, color, -1, cv2.LINE_AA)\n",
    "\n",
    "        # líneas\n",
    "        for a, b in skeleton:\n",
    "            if conf[a] >= conf_th and conf[b] >= conf_th:\n",
    "                xa, ya = pts[a]; xb, yb = pts[b]\n",
    "                if 0 <= xa < w and 0 <= ya < h and 0 <= xb < w and 0 <= yb < h:\n",
    "                    cv2.line(frame, (int(xa), int(ya)), (int(xb), int(yb)), color, 2, cv2.LINE_AA)\n",
    "\n",
    "# =============== MAIN ===============\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(VIDEO_IN)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"No se pudo abrir: {VIDEO_IN}\")\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    W   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    H   = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    writer = None\n",
    "    if VIDEO_OUT:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "        Path(VIDEO_OUT).parent.mkdir(parents=True, exist_ok=True)\n",
    "        writer = cv2.VideoWriter(VIDEO_OUT, fourcc, fps, (W, H))\n",
    "\n",
    "    model = YOLO(MODEL_PATH)\n",
    "\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "\n",
    "        # Inference en el frame (numpy)\n",
    "        res = model.predict(\n",
    "            source=frame,\n",
    "            imgsz=IMGSZ,\n",
    "            conf=CONF_TH,\n",
    "            iou=IOU_TH,\n",
    "            verbose=False\n",
    "        )[0]\n",
    "\n",
    "        # Keypoints: (num_personas, 17, 2) y (num_personas, 17)\n",
    "        kps_xy   = None\n",
    "        kps_conf = None\n",
    "        if res.keypoints is not None:\n",
    "            # Ultralytics expone .xy y .confidence\n",
    "            # Algunas versiones usan .conf; cubrimos ambos.\n",
    "            kps_xy = res.keypoints.xy.cpu().numpy()                    # (N,17,2)\n",
    "            kps_conf = getattr(res.keypoints, \"confidence\", None)\n",
    "            if kps_conf is None:\n",
    "                kps_conf = getattr(res.keypoints, \"conf\", None)\n",
    "            kps_conf = kps_conf.cpu().numpy() if kps_conf is not None else None\n",
    "\n",
    "        if kps_xy is not None and kps_xy.size > 0:\n",
    "            draw_poses(frame, kps_xy, kps_conf, SKELETON, DRAW_CONF)\n",
    "\n",
    "        cv2.imshow(\"YOLOv11 Pose Overlay\", frame)\n",
    "        if writer: writer.write(frame)\n",
    "\n",
    "        key = cv2.waitKey(max(1, int(1000/fps))) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    if writer: writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f4cb3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11m-pose summary (fused): 134 layers, 20,889,004 parameters, 0 gradients, 71.4 GFLOPs\n",
      "✓ Guardado C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\key.npz\n",
      "kps: (1199, 5, 17, 3) | frames: 1199 | labels_in: 1199 | offset: 0\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np, torch, json\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "# ========= CONFIG =========\n",
    "VIDEO_PATH  = r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\1_069_1.mp4\"\n",
    "LABEL_NPY   = r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\anomaly_labels\\1_069_1.npy\"        # etiquetas 0/1 por frame (del anotador)\n",
    "OUT_NPZ     = r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\key.npz\"\n",
    "\n",
    "MODEL       = \"yolo11m-pose.pt\"            # calidad>velocidad (cámbialo a 'yolo11s-pose.pt' si tu GPU es débil)\n",
    "IMGSZ       = 960                           # 896–960 = keypoints más definidos\n",
    "CONF_TH     = 0.25\n",
    "IOU_TH      = 0.50\n",
    "TOPK        = 5                             # máximo personas por frame que guardas\n",
    "\n",
    "# Opcional: si sabes que tus labels empiezan en un frame distinto (offset en frames de VIDEO → labels)\n",
    "START_OFFSET = 0                            # positivo: etiquetas comienzan después; negativo: antes\n",
    "\n",
    "# ========= UTILS =========\n",
    "def build_label_mapping(n_video_frames, labels, start_offset=0):\n",
    "    \"\"\"\n",
    "    Devuelve:\n",
    "      labels_aligned: len == n_video_frames\n",
    "      map_idx: para cada frame de video (0..Fv-1), qué índice de label se usó (o -1 si fuera de rango)\n",
    "    Regla: vecino más cercano con offset.\n",
    "    \"\"\"\n",
    "    L = len(labels)\n",
    "    map_idx = np.full(n_video_frames, -1, dtype=np.int32)\n",
    "\n",
    "    if L <= 1:\n",
    "        # Trivial: todo cero o único valor\n",
    "        if L == 1:\n",
    "            map_idx[:] = 0\n",
    "        return (labels[map_idx.clip(0, L-1)] if L else np.zeros(n_video_frames, dtype=np.int32)), map_idx\n",
    "\n",
    "    # mapea [0..Fv-1] → [0..L-1] con offset\n",
    "    # índice proporcional + desplazamiento\n",
    "    src = np.linspace(0, L - 1, num=n_video_frames)\n",
    "    src = np.round(src).astype(int) + start_offset\n",
    "    src = np.clip(src, 0, L - 1)\n",
    "    map_idx = src\n",
    "    labels_aligned = labels[map_idx]\n",
    "    return labels_aligned.astype(labels.dtype), map_idx\n",
    "\n",
    "# ========= MAIN =========\n",
    "def main():\n",
    "    # carga video y labels\n",
    "    labels = np.load(LABEL_NPY)  # vector 0/1 por frame (o multiclase)\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    assert cap.isOpened(), f\"No se pudo abrir el video: {VIDEO_PATH}\"\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    W   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    H   = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    N   = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # modelo\n",
    "    model = YOLO(MODEL)\n",
    "    if torch.cuda.is_available():\n",
    "        model.to(\"cuda\")\n",
    "    model.fuse()\n",
    "\n",
    "    # salida\n",
    "    kps = np.full((N, TOPK, 17, 3), np.nan, dtype=np.float32)\n",
    "    per_frame_counts = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "    # extrae\n",
    "    idx = 0\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok: break\n",
    "\n",
    "        r = model.predict(\n",
    "            frame, imgsz=IMGSZ, conf=CONF_TH, iou=IOU_TH,\n",
    "            verbose=False, half=torch.cuda.is_available()\n",
    "        )[0]\n",
    "\n",
    "        if r.keypoints is not None and r.keypoints.xy is not None and r.keypoints.xy.shape[0] > 0:\n",
    "            xy = r.keypoints.xy.cpu().numpy()  # (P,17,2)\n",
    "            c  = getattr(r.keypoints, \"confidence\", None)\n",
    "            if c is None: c = getattr(r.keypoints, \"conf\", None)\n",
    "            c  = c.cpu().numpy() if c is not None else np.ones(xy.shape[:2], dtype=np.float32)\n",
    "\n",
    "            # ordena personas por confianza media\n",
    "            order = np.argsort(-c.mean(axis=1))\n",
    "            xy, c = xy[order], c[order]\n",
    "            P = min(xy.shape[0], TOPK)\n",
    "            per_frame_counts[idx] = P\n",
    "\n",
    "            # (x,y,conf)\n",
    "            arr = np.concatenate([xy[:P], c[:P, :, None]], axis=-1)  # (P,17,3)\n",
    "            kps[idx, :P] = arr.astype(np.float32)\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # alinear etiquetas al número de frames del VIDEO\n",
    "    labels_aligned, map_idx = build_label_mapping(N, labels, start_offset=START_OFFSET)\n",
    "\n",
    "    meta = {\n",
    "        \"video_path\": str(VIDEO_PATH),\n",
    "        \"labels_path\": str(LABEL_NPY),\n",
    "        \"fps_video\": float(fps),\n",
    "        \"width\": int(W),\n",
    "        \"height\": int(H),\n",
    "        \"n_video_frames\": int(N),\n",
    "        \"labels_len\": int(len(labels)),\n",
    "        \"start_offset\": int(START_OFFSET),\n",
    "        \"imgsz\": int(IMGSZ),\n",
    "        \"model\": MODEL,\n",
    "        \"conf_th\": float(CONF_TH),\n",
    "        \"iou_th\": float(IOU_TH),\n",
    "        \"topk\": int(TOPK)\n",
    "    }\n",
    "\n",
    "    Path(OUT_NPZ).parent.mkdir(parents=True, exist_ok=True)\n",
    "    np.savez_compressed(\n",
    "        OUT_NPZ,\n",
    "        kps=kps,\n",
    "        per_frame_counts=per_frame_counts,\n",
    "        labels_aligned=labels_aligned,\n",
    "        map_label_idx=map_idx,\n",
    "        meta=json.dumps(meta)\n",
    "    )\n",
    "    print(f\"✓ Guardado {OUT_NPZ}\")\n",
    "    print(f\"kps: {kps.shape} | frames: {N} | labels_in: {len(labels)} | offset: {START_OFFSET}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba55c4b",
   "metadata": {},
   "source": [
    "PROBAR POR NPZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3251b7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kps: (181, 1, 17, 3) dtype: float32\n",
      "per_frame_counts: (181,) sum personas: 181\n",
      "labels_aligned: (181,) positivos: 33\n",
      "meta: {'video_path': 'C:\\\\Users\\\\Usuario\\\\Documents\\\\GitHub\\\\tesis-deteccionar-sistema\\\\Dataset_Le21+GMDCSA24\\\\VideosFall\\\\video (5).avi', 'labels_path': 'C:\\\\Users\\\\Usuario\\\\Documents\\\\GitHub\\\\tesis-deteccionar-sistema\\\\Dataset_Le21+GMDCSA24\\\\Annotation_files\\\\video (5).txt', 'fps_video': 25.0, 'width': 320, 'height': 240, 'n_video_frames': 181, 'labels_len': 181, 'imgsz': 960, 'model': 'yolo11m-pose.pt', 'conf_th': 0.25, 'iou_th': 0.6, 'topk': 1}\n",
      "✓ NPZ ok a nivel de forma/básicos\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, json\n",
    "\n",
    "NPZ_PATH = r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\out_npz_fall\\video (5).npz\"\n",
    "z = np.load(NPZ_PATH, allow_pickle=True)\n",
    "\n",
    "kps = z[\"kps\"]                      # [F, K, 17, 3] (x,y,conf) con NaN\n",
    "counts = z[\"per_frame_counts\"]      # [F]\n",
    "labels = z.get(\"labels_aligned\", None)  # opcional\n",
    "map_idx = z.get(\"map_label_idx\", None)  # opcional\n",
    "meta = json.loads(z[\"meta\"].item() if hasattr(z[\"meta\"], \"item\") else z[\"meta\"].tolist())\n",
    "\n",
    "print(\"kps:\", kps.shape, \"dtype:\", kps.dtype)\n",
    "print(\"per_frame_counts:\", counts.shape, \"sum personas:\", int(counts.sum()))\n",
    "if labels is not None: print(\"labels_aligned:\", labels.shape, \"positivos:\", int(labels.sum()))\n",
    "print(\"meta:\", meta)\n",
    "\n",
    "# Chequeos rápidos\n",
    "F, K = kps.shape[:2]\n",
    "assert counts.shape[0] == F, \"counts desalineado con frames\"\n",
    "assert np.isfinite(kps[..., :2][~np.isnan(kps[..., :2])]).all(), \"x/y con inf\"\n",
    "print(\"✓ NPZ ok a nivel de forma/básicos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9e0592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np, random\n",
    "\n",
    "SKELETON = [(0,1),(0,2),(1,3),(2,4),(5,6),(5,7),(7,9),(6,8),(8,10),\n",
    "            (5,11),(6,12),(11,12),(11,13),(13,15),(12,14),(14,16)]\n",
    "\n",
    "def draw_frame_from_npz(canvas, kps_frame, draw_conf=0.2):\n",
    "    H, W = canvas.shape[:2]\n",
    "    colors = [(255,0,0),(0,255,0),(0,0,255),(255,255,0),(255,0,255)]\n",
    "    for p in range(kps_frame.shape[0]):\n",
    "        color = colors[p % len(colors)]\n",
    "        pts = kps_frame[p, :, :2]\n",
    "        conf = kps_frame[p, :, 2]\n",
    "        if np.isnan(pts).all(): continue\n",
    "        # puntos\n",
    "        for (x,y), c in zip(pts, conf):\n",
    "            if not np.isnan(x) and not np.isnan(y) and c >= draw_conf and 0<=x<W and 0<=y<H:\n",
    "                cv2.circle(canvas, (int(x),int(y)), 2, color, -1, cv2.LINE_AA)\n",
    "        # líneas\n",
    "        for a,b in SKELETON:\n",
    "            xa,ya = pts[a]; xb,yb = pts[b]\n",
    "            ca,cb = conf[a], conf[b]\n",
    "            if (not np.isnan([xa,ya,xb,yb]).any() and ca>=draw_conf and cb>=draw_conf and\n",
    "                0<=xa<W and 0<=ya<H and 0<=xb<W and 0<=yb<H):\n",
    "                cv2.line(canvas, (int(xa),int(ya)), (int(xb),int(yb)), color, 2, cv2.LINE_AA)\n",
    "    return canvas\n",
    "\n",
    "W, H = int(meta[\"width\"]), int(meta[\"height\"])\n",
    "f = random.randrange(kps.shape[0])\n",
    "canvas = np.zeros((H, W, 3), np.uint8)\n",
    "img = draw_frame_from_npz(canvas, kps[f])\n",
    "cv2.imshow(f\"Frame {f}\", img); cv2.waitKey(0); cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b6dc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "VIDEO_PATH = meta.get(\"video_path\", \"\")  # lo guardaste en meta\n",
    "cap = cv2.VideoCapture(VIDEO_PATH) if VIDEO_PATH else None\n",
    "F = kps.shape[0]\n",
    "draw_conf = 0.2\n",
    "\n",
    "def draw_on(frame, kps_frame):\n",
    "    return draw_frame_from_npz(frame, kps_frame, draw_conf)\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    if cap is not None:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok or i>=F: break\n",
    "    else:\n",
    "        # Sin video: lienzo negro con tamaño meta\n",
    "        frame = np.zeros((int(meta[\"height\"]), int(meta[\"width\"]), 3), np.uint8)\n",
    "        if i>=F: break\n",
    "\n",
    "    frame = draw_on(frame, kps[i])\n",
    "\n",
    "    # Mostrar etiqueta si existe\n",
    "    if labels is not None:\n",
    "        lab = int(labels[i])\n",
    "        txt = \"ANOMALIA\" if lab==1 else \"NORMAL\"\n",
    "        color = (0,0,255) if lab==1 else (0,200,0)\n",
    "        cv2.putText(frame, f\"{txt}\", (20,60), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 3, cv2.LINE_AA)\n",
    "    cv2.putText(frame, f\"Frame {i}\", (20,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"NPZ overlay\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'): break\n",
    "    i += 1\n",
    "\n",
    "if cap is not None: cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af975b31",
   "metadata": {},
   "source": [
    "SE TERMINA LAS VISUALIZACIONES POR NPZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015076e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\out_npz\\1_002_0.npz ===\n",
      "Claves: ['kps', 'per_frame_counts', 'labels_aligned', 'meta']\n",
      "\n",
      "[kps] shape=(5399, 5, 17, 3) dtype=float32\n",
      "  conf min/max: 0.0011 / 1.0000\n",
      "  Ejemplo f0, p0, nose (x,y,conf) = [899.5, 308.5, 0.57470703125]\n",
      "\n",
      "[labels_aligned] shape=(5399,) dtype=float64\n",
      "  únicos=[0.0]  counts=[5399]  pos_ratio=0.0000\n",
      "\n",
      "[per_frame_counts] shape=(5399,)  mean=1.828  p50=2  p95=3\n",
      "\n",
      "[meta]\n",
      "  video_path: C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\CHAD_VIDEOS\\1_002_0.mp4\n",
      "  labels_path: C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\anomaly_labels\\1_002_0.npy\n",
      "  fps_video: 29.97002997002997\n",
      "  width: 1920\n",
      "  height: 1080\n",
      "  n_video_frames: 5399\n",
      "  labels_len: 5399\n",
      "  imgsz: 960\n",
      "  model: yolo11m-pose.pt\n",
      "  topk: 5\n"
     ]
    }
   ],
   "source": [
    "# inspect_one_npz.py\n",
    "import numpy as np, json\n",
    "\n",
    "NPZ_PATH = r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\out_npz\\1_002_0.npz\"  # <-- cambia\n",
    "\n",
    "def main():\n",
    "    z = np.load(NPZ_PATH, allow_pickle=True)\n",
    "    print(f\"\\n=== {NPZ_PATH} ===\")\n",
    "    print(\"Claves:\", list(z.files))\n",
    "\n",
    "    # kps: [F, K, 17, 3] -> (x, y, conf_joint)\n",
    "    if \"kps\" in z:\n",
    "        kps = z[\"kps\"]\n",
    "        print(f\"\\n[kps] shape={kps.shape} dtype={kps.dtype}\")\n",
    "        F, K, J, C = kps.shape\n",
    "        conf = kps[..., 2]\n",
    "        conf_finite = conf[np.isfinite(conf)]\n",
    "        if conf_finite.size:\n",
    "            print(f\"  conf min/max: {conf_finite.min():.4f} / {conf_finite.max():.4f}\")\n",
    "        # ejemplo rápido del frame 0, persona 0 (si existe)\n",
    "        f0 = 0\n",
    "        if F and K:\n",
    "            p0_valid = ~np.isnan(kps[f0, 0, :, 0]).all()\n",
    "            if p0_valid:\n",
    "                nose = kps[f0, 0, 0]     # joint 0 (nariz)\n",
    "                print(f\"  Ejemplo f{f0}, p0, nose (x,y,conf) = {nose.tolist()}\")\n",
    "\n",
    "    # labels_aligned: [F]\n",
    "    if \"labels_aligned\" in z:\n",
    "        labels = z[\"labels_aligned\"]\n",
    "        uniq, cnt = np.unique(labels, return_counts=True)\n",
    "        ratio = float(labels.mean()) if labels.size else 0.0\n",
    "        print(f\"\\n[labels_aligned] shape={labels.shape} dtype={labels.dtype}\")\n",
    "        print(f\"  únicos={uniq.tolist()}  counts={cnt.tolist()}  pos_ratio={ratio:.4f}\")\n",
    "\n",
    "    # per_frame_counts: [F]\n",
    "    if \"per_frame_counts\" in z:\n",
    "        c = z[\"per_frame_counts\"]\n",
    "        if c.size:\n",
    "            print(f\"\\n[per_frame_counts] shape={c.shape}  mean={c.mean():.3f}  p50={np.percentile(c,50):.0f}  p95={np.percentile(c,95):.0f}\")\n",
    "\n",
    "    # meta (json)\n",
    "    if \"meta\" in z:\n",
    "        meta_raw = z[\"meta\"]\n",
    "        try:\n",
    "            meta = json.loads(meta_raw.item() if hasattr(meta_raw, \"item\") else meta_raw)\n",
    "        except Exception:\n",
    "            meta = {}\n",
    "        keep = [\"video_path\",\"labels_path\",\"fps_video\",\"width\",\"height\",\"n_video_frames\",\"labels_len\",\"imgsz\",\"model\",\"topk\"]\n",
    "        print(\"\\n[meta]\")\n",
    "        for k in keep:\n",
    "            if k in meta:\n",
    "                print(f\"  {k}: {meta[k]}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c0c264c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_002_0.npz                    | frames= 5399  pos_ratio=0.0000  ventanas: pos=    0 neg=  671 tot=  671\n",
      "1_003_0.npz                    | frames= 6299  pos_ratio=0.0000  ventanas: pos=    0 neg=  784 tot=  784\n",
      "1_033_0.npz                    | frames= 1799  pos_ratio=0.0000  ventanas: pos=    0 neg=  221 tot=  221\n",
      "1_069_1.npz                    | frames= 1199  pos_ratio=0.7314  ventanas: pos=  110 neg=   36 tot=  146\n",
      "1_070_1.npz                    | frames=  449  pos_ratio=0.4410  ventanas: pos=   25 neg=   28 tot=   53\n",
      "1_071_1.npz                    | frames=  599  pos_ratio=0.5376  ventanas: pos=   40 neg=   31 tot=   71\n",
      "1_072_1.npz                    | frames=  749  pos_ratio=0.8198  ventanas: pos=   77 neg=   13 tot=   90\n",
      "1_073_1.npz                    | frames=  449  pos_ratio=0.3341  ventanas: pos=   19 neg=   34 tot=   53\n",
      "1_074_1.npz                    | frames=  449  pos_ratio=0.2294  ventanas: pos=   13 neg=   40 tot=   53\n",
      "1_075_1.npz                    | frames=  449  pos_ratio=0.2205  ventanas: pos=   12 neg=   41 tot=   53\n",
      "1_076_1.npz                    | frames=  449  pos_ratio=0.2695  ventanas: pos=   15 neg=   38 tot=   53\n",
      "1_078_1.npz                    | frames= 1199  pos_ratio=0.5430  ventanas: pos=   81 neg=   65 tot=  146\n",
      "1_079_1.npz                    | frames=  449  pos_ratio=0.3920  ventanas: pos=   22 neg=   31 tot=   53\n",
      "1_081_1.npz                    | frames=  389  pos_ratio=0.3676  ventanas: pos=   18 neg=   27 tot=   45\n",
      "1_082_1.npz                    | frames=  449  pos_ratio=0.3541  ventanas: pos=   20 neg=   33 tot=   53\n",
      "1_083_1.npz                    | frames=  449  pos_ratio=0.4722  ventanas: pos=   26 neg=   27 tot=   53\n",
      "1_084_1.npz                    | frames= 1199  pos_ratio=0.6997  ventanas: pos=  105 neg=   41 tot=  146\n",
      "1_087_1.npz                    | frames=  509  pos_ratio=0.2770  ventanas: pos=   18 neg=   42 tot=   60\n",
      "1_088_1.npz                    | frames= 1349  pos_ratio=0.6019  ventanas: pos=  102 neg=   63 tot=  165\n",
      "1_091_1.npz                    | frames= 1349  pos_ratio=0.8050  ventanas: pos=  136 neg=   29 tot=  165\n",
      "1_093_1.npz                    | frames= 4499  pos_ratio=0.5912  ventanas: pos=  332 neg=  227 tot=  559\n",
      "1_094_1.npz                    | frames= 1949  pos_ratio=0.6136  ventanas: pos=  151 neg=   89 tot=  240\n",
      "1_095_1.npz                    | frames=  419  pos_ratio=0.3294  ventanas: pos=   18 neg=   31 tot=   49\n",
      "1_096_1.npz                    | frames=  299  pos_ratio=0.3077  ventanas: pos=   11 neg=   23 tot=   34\n",
      "2_012_0.npz                    | frames= 5400  pos_ratio=0.0000  ventanas: pos=    0 neg=  672 tot=  672\n",
      "2_047_0.npz                    | frames= 2700  pos_ratio=0.0000  ventanas: pos=    0 neg=  334 tot=  334\n",
      "2_048_0.npz                    | frames=  600  pos_ratio=0.0000  ventanas: pos=    0 neg=   72 tot=   72\n",
      "2_049_0.npz                    | frames=  600  pos_ratio=0.0000  ventanas: pos=    0 neg=   72 tot=   72\n",
      "2_050_0.npz                    | frames= 5400  pos_ratio=0.0000  ventanas: pos=    0 neg=  672 tot=  672\n",
      "2_051_0.npz                    | frames= 1950  pos_ratio=0.0000  ventanas: pos=    0 neg=  240 tot=  240\n",
      "2_052_0.npz                    | frames= 2790  pos_ratio=0.0000  ventanas: pos=    0 neg=  345 tot=  345\n",
      "2_053_0.npz                    | frames=  750  pos_ratio=0.0000  ventanas: pos=    0 neg=   90 tot=   90\n",
      "2_054_0.npz                    | frames= 1200  pos_ratio=0.0000  ventanas: pos=    0 neg=  147 tot=  147\n",
      "2_055_0.npz                    | frames= 1350  pos_ratio=0.0000  ventanas: pos=    0 neg=  165 tot=  165\n",
      "2_063_0.npz                    | frames= 5691  pos_ratio=0.0000  ventanas: pos=    0 neg=  708 tot=  708\n",
      "2_064_1.npz                    | frames=  450  pos_ratio=0.4244  ventanas: pos=   24 neg=   29 tot=   53\n",
      "2_065_1.npz                    | frames= 1350  pos_ratio=0.4837  ventanas: pos=   82 neg=   83 tot=  165\n",
      "2_066_1.npz                    | frames=  600  pos_ratio=0.6800  ventanas: pos=   51 neg=   21 tot=   72\n",
      "2_067_1.npz                    | frames=  750  pos_ratio=0.1947  ventanas: pos=   19 neg=   71 tot=   90\n",
      "2_068_1.npz                    | frames= 1050  pos_ratio=0.5305  ventanas: pos=   69 neg=   59 tot=  128\n",
      "2_069_1.npz                    | frames=  750  pos_ratio=0.5240  ventanas: pos=   49 neg=   41 tot=   90\n",
      "2_070_1.npz                    | frames=  600  pos_ratio=0.1983  ventanas: pos=   15 neg=   57 tot=   72\n",
      "2_071_1.npz                    | frames=  900  pos_ratio=0.3989  ventanas: pos=   46 neg=   63 tot=  109\n",
      "2_072_1.npz                    | frames=  450  pos_ratio=0.3289  ventanas: pos=   18 neg=   35 tot=   53\n",
      "2_073_1.npz                    | frames= 1350  pos_ratio=0.1074  ventanas: pos=   18 neg=  147 tot=  165\n",
      "2_074_1.npz                    | frames= 1050  pos_ratio=0.6295  ventanas: pos=   83 neg=   45 tot=  128\n",
      "2_075_1.npz                    | frames=  450  pos_ratio=0.3533  ventanas: pos=   20 neg=   33 tot=   53\n",
      "2_076_1.npz                    | frames=  750  pos_ratio=0.4240  ventanas: pos=   40 neg=   50 tot=   90\n",
      "2_077_1.npz                    | frames=  360  pos_ratio=0.4750  ventanas: pos=   20 neg=   22 tot=   42\n",
      "2_078_1.npz                    | frames=  450  pos_ratio=0.3400  ventanas: pos=   19 neg=   34 tot=   53\n",
      "2_079_1.npz                    | frames=  600  pos_ratio=0.6017  ventanas: pos=   45 neg=   27 tot=   72\n",
      "2_080_1.npz                    | frames= 1800  pos_ratio=0.5889  ventanas: pos=  134 neg=   88 tot=  222\n",
      "2_081_1.npz                    | frames=  510  pos_ratio=0.8353  ventanas: pos=   53 neg=    7 tot=   60\n",
      "2_082_1.npz                    | frames= 1350  pos_ratio=0.1156  ventanas: pos=   19 neg=  146 tot=  165\n",
      "2_083_1.npz                    | frames= 2850  pos_ratio=0.4151  ventanas: pos=  150 neg=  203 tot=  353\n",
      "2_084_1.npz                    | frames=  600  pos_ratio=0.5417  ventanas: pos=   41 neg=   31 tot=   72\n",
      "2_085_1.npz                    | frames=  300  pos_ratio=0.2933  ventanas: pos=   11 neg=   23 tot=   34\n",
      "2_086_1.npz                    | frames= 1500  pos_ratio=0.6007  ventanas: pos=  113 neg=   71 tot=  184\n",
      "2_087_1.npz                    | frames=  750  pos_ratio=0.3347  ventanas: pos=   31 neg=   59 tot=   90\n",
      "2_088_1.npz                    | frames=  660  pos_ratio=0.3788  ventanas: pos=   29 neg=   50 tot=   79\n",
      "2_089_1.npz                    | frames= 1050  pos_ratio=0.5305  ventanas: pos=   70 neg=   58 tot=  128\n",
      "2_090_1.npz                    | frames= 5400  pos_ratio=0.4878  ventanas: pos=  331 neg=  341 tot=  672\n",
      "2_091_0.npz                    | frames= 2400  pos_ratio=0.0000  ventanas: pos=    0 neg=  297 tot=  297\n",
      "2_092_1.npz                    | frames=  450  pos_ratio=0.1133  ventanas: pos=    6 neg=   47 tot=   53\n",
      "2_093_1.npz                    | frames= 1950  pos_ratio=0.6697  ventanas: pos=  165 neg=   75 tot=  240\n",
      "2_094_1.npz                    | frames= 3600  pos_ratio=0.0481  ventanas: pos=   21 neg=  426 tot=  447\n",
      "2_095_1.npz                    | frames=  450  pos_ratio=0.5156  ventanas: pos=   29 neg=   24 tot=   53\n",
      "2_096_1.npz                    | frames=  450  pos_ratio=0.4400  ventanas: pos=   25 neg=   28 tot=   53\n",
      "3_001_0.npz                    | frames= 5398  pos_ratio=0.0000  ventanas: pos=    0 neg=  671 tot=  671\n",
      "3_002_0.npz                    | frames= 5398  pos_ratio=0.0000  ventanas: pos=    0 neg=  671 tot=  671\n",
      "3_003_0.npz                    | frames= 5398  pos_ratio=0.0000  ventanas: pos=    0 neg=  671 tot=  671\n",
      "3_027_0.npz                    | frames= 5398  pos_ratio=0.0000  ventanas: pos=    0 neg=  671 tot=  671\n",
      "3_028_0.npz                    | frames= 5398  pos_ratio=0.0000  ventanas: pos=    0 neg=  671 tot=  671\n",
      "3_029_0.npz                    | frames= 5398  pos_ratio=0.0000  ventanas: pos=    0 neg=  671 tot=  671\n",
      "3_030_0.npz                    | frames= 3299  pos_ratio=0.0000  ventanas: pos=    0 neg=  409 tot=  409\n",
      "3_031_0.npz                    | frames= 2099  pos_ratio=0.0000  ventanas: pos=    0 neg=  259 tot=  259\n",
      "3_032_0.npz                    | frames= 1649  pos_ratio=0.0000  ventanas: pos=    0 neg=  203 tot=  203\n",
      "3_033_0.npz                    | frames= 2999  pos_ratio=0.0000  ventanas: pos=    0 neg=  371 tot=  371\n",
      "3_034_0.npz                    | frames= 2699  pos_ratio=0.0000  ventanas: pos=    0 neg=  334 tot=  334\n",
      "3_035_0.npz                    | frames= 1353  pos_ratio=0.0000  ventanas: pos=    0 neg=  166 tot=  166\n",
      "3_056_0.npz                    | frames= 5398  pos_ratio=0.0000  ventanas: pos=    0 neg=  671 tot=  671\n",
      "3_057_0.npz                    | frames= 3299  pos_ratio=0.0000  ventanas: pos=    0 neg=  409 tot=  409\n",
      "3_074_0.npz                    | frames= 1010  pos_ratio=0.0000  ventanas: pos=    0 neg=  123 tot=  123\n",
      "3_074_1.npz                    | frames=  599  pos_ratio=0.0684  ventanas: pos=    5 neg=   66 tot=   71\n",
      "3_075_1.npz                    | frames=  906  pos_ratio=0.2042  ventanas: pos=   23 neg=   87 tot=  110\n",
      "3_076_1.npz                    | frames= 1492  pos_ratio=0.5871  ventanas: pos=  109 neg=   74 tot=  183\n",
      "3_077_1.npz                    | frames=  899  pos_ratio=0.3949  ventanas: pos=   44 neg=   65 tot=  109\n",
      "3_078_1.npz                    | frames= 1499  pos_ratio=0.1701  ventanas: pos=   31 neg=  153 tot=  184\n",
      "3_079_1.npz                    | frames= 1349  pos_ratio=0.3988  ventanas: pos=   68 neg=   97 tot=  165\n",
      "3_080_1.npz                    | frames=  899  pos_ratio=0.2647  ventanas: pos=   30 neg=   79 tot=  109\n",
      "3_081_1.npz                    | frames=  890  pos_ratio=0.2157  ventanas: pos=   24 neg=   84 tot=  108\n",
      "3_082_1.npz                    | frames=  899  pos_ratio=0.1402  ventanas: pos=   16 neg=   93 tot=  109\n",
      "3_083_1.npz                    | frames=  599  pos_ratio=0.2638  ventanas: pos=   20 neg=   51 tot=   71\n",
      "3_084_1.npz                    | frames=  731  pos_ratio=0.2202  ventanas: pos=   20 neg=   68 tot=   88\n",
      "3_085_1.npz                    | frames=  599  pos_ratio=0.2120  ventanas: pos=   16 neg=   55 tot=   71\n",
      "3_086_1.npz                    | frames= 2699  pos_ratio=0.2597  ventanas: pos=   87 neg=  247 tot=  334\n",
      "3_087_1.npz                    | frames=  599  pos_ratio=0.3072  ventanas: pos=   23 neg=   48 tot=   71\n",
      "3_088_1.npz                    | frames=  599  pos_ratio=0.1252  ventanas: pos=    9 neg=   62 tot=   71\n",
      "3_089_1.npz                    | frames=  899  pos_ratio=0.6463  ventanas: pos=   72 neg=   37 tot=  109\n",
      "3_090_1.npz                    | frames=  599  pos_ratio=0.2454  ventanas: pos=   19 neg=   52 tot=   71\n",
      "3_091_1.npz                    | frames=  599  pos_ratio=0.2771  ventanas: pos=   20 neg=   51 tot=   71\n",
      "3_092_1.npz                    | frames= 2099  pos_ratio=0.4574  ventanas: pos=  120 neg=  139 tot=  259\n",
      "3_093_1.npz                    | frames= 1049  pos_ratio=0.3203  ventanas: pos=   41 neg=   87 tot=  128\n",
      "3_094_1.npz                    | frames=  749  pos_ratio=0.2563  ventanas: pos=   24 neg=   66 tot=   90\n",
      "3_095_1.npz                    | frames=  749  pos_ratio=0.4593  ventanas: pos=   43 neg=   47 tot=   90\n",
      "3_096_1.npz                    | frames=  449  pos_ratio=0.4254  ventanas: pos=   24 neg=   29 tot=   53\n",
      "3_097_1.npz                    | frames=  749  pos_ratio=0.3017  ventanas: pos=   29 neg=   61 tot=   90\n",
      "3_098_1.npz                    | frames= 1499  pos_ratio=0.3189  ventanas: pos=   59 neg=  125 tot=  184\n",
      "3_099_1.npz                    | frames= 1649  pos_ratio=0.7890  ventanas: pos=  162 neg=   41 tot=  203\n",
      "3_100_1.npz                    | frames=  599  pos_ratio=0.6361  ventanas: pos=   48 neg=   23 tot=   71\n",
      "3_101_1.npz                    | frames= 4348  pos_ratio=0.6812  ventanas: pos=  372 neg=  168 tot=  540\n",
      "3_102_1.npz                    | frames= 2399  pos_ratio=0.5469  ventanas: pos=  164 neg=  132 tot=  296\n",
      "3_103_1.npz                    | frames=  449  pos_ratio=0.2851  ventanas: pos=   16 neg=   37 tot=   53\n",
      "3_104_1.npz                    | frames=  749  pos_ratio=0.4513  ventanas: pos=   42 neg=   48 tot=   90\n",
      "3_105_1.npz                    | frames=  601  pos_ratio=0.4409  ventanas: pos=   33 neg=   39 tot=   72\n",
      "3_106_1.npz                    | frames=  449  pos_ratio=0.5679  ventanas: pos=   32 neg=   21 tot=   53\n",
      "4_001_0.npz                    | frames= 5249  pos_ratio=0.0000  ventanas: pos=    0 neg=  653 tot=  653\n",
      "4_002_0.npz                    | frames= 5399  pos_ratio=0.0000  ventanas: pos=    0 neg=  671 tot=  671\n",
      "4_003_0.npz                    | frames= 1709  pos_ratio=0.0000  ventanas: pos=    0 neg=  210 tot=  210\n",
      "4_004_0.npz                    | frames= 1829  pos_ratio=0.0000  ventanas: pos=    0 neg=  225 tot=  225\n",
      "4_005_0.npz                    | frames= 5849  pos_ratio=0.0000  ventanas: pos=    0 neg=  728 tot=  728\n",
      "4_006_0.npz                    | frames= 5399  pos_ratio=0.0000  ventanas: pos=    0 neg=  671 tot=  671\n",
      "4_007_0.npz                    | frames= 3455  pos_ratio=0.0000  ventanas: pos=    0 neg=  428 tot=  428\n",
      "4_039_0.npz                    | frames= 2549  pos_ratio=0.0000  ventanas: pos=    0 neg=  315 tot=  315\n",
      "4_040_0.npz                    | frames= 1949  pos_ratio=0.0000  ventanas: pos=    0 neg=  240 tot=  240\n",
      "4_054_0.npz                    | frames= 1649  pos_ratio=0.0000  ventanas: pos=    0 neg=  203 tot=  203\n",
      "4_055_0.npz                    | frames=  599  pos_ratio=0.0000  ventanas: pos=    0 neg=   71 tot=   71\n",
      "4_056_0.npz                    | frames= 1169  pos_ratio=0.0000  ventanas: pos=    0 neg=  143 tot=  143\n",
      "4_057_0.npz                    | frames=  989  pos_ratio=0.0000  ventanas: pos=    0 neg=  120 tot=  120\n",
      "4_058_0.npz                    | frames= 5249  pos_ratio=0.0000  ventanas: pos=    0 neg=  653 tot=  653\n",
      "4_059_0.npz                    | frames= 3599  pos_ratio=0.0000  ventanas: pos=    0 neg=  446 tot=  446\n",
      "4_060_0.npz                    | frames=  629  pos_ratio=0.0000  ventanas: pos=    0 neg=   75 tot=   75\n",
      "4_061_0.npz                    | frames=  899  pos_ratio=0.0000  ventanas: pos=    0 neg=  109 tot=  109\n",
      "4_062_0.npz                    | frames= 4079  pos_ratio=0.0000  ventanas: pos=    0 neg=  506 tot=  506\n",
      "4_063_0.npz                    | frames= 3449  pos_ratio=0.0000  ventanas: pos=    0 neg=  428 tot=  428\n",
      "4_073_0.npz                    | frames= 5399  pos_ratio=0.0000  ventanas: pos=    0 neg=  671 tot=  671\n",
      "4_074_0.npz                    | frames=  398  pos_ratio=0.0000  ventanas: pos=    0 neg=   46 tot=   46\n",
      "4_075_0.npz                    | frames=  149  pos_ratio=0.0000  ventanas: pos=    0 neg=   15 tot=   15\n",
      "4_076_1.npz                    | frames=  419  pos_ratio=0.5680  ventanas: pos=   30 neg=   19 tot=   49\n",
      "4_077_1.npz                    | frames=  329  pos_ratio=0.6565  ventanas: pos=   28 neg=   10 tot=   38\n",
      "4_078_1.npz                    | frames=  299  pos_ratio=0.4548  ventanas: pos=   17 neg=   17 tot=   34\n",
      "4_080_1.npz                    | frames=  659  pos_ratio=0.5630  ventanas: pos=   47 neg=   32 tot=   79\n",
      "4_081_1.npz                    | frames=  599  pos_ratio=0.4407  ventanas: pos=   33 neg=   38 tot=   71\n",
      "4_082_1.npz                    | frames=  929  pos_ratio=0.8278  ventanas: pos=   96 neg=   17 tot=  113\n",
      "4_083_1.npz                    | frames=  599  pos_ratio=0.6311  ventanas: pos=   48 neg=   23 tot=   71\n",
      "4_084_1.npz                    | frames=  449  pos_ratio=0.3541  ventanas: pos=   20 neg=   33 tot=   53\n",
      "4_085_1.npz                    | frames=  419  pos_ratio=0.2554  ventanas: pos=   14 neg=   35 tot=   49\n",
      "4_086_1.npz                    | frames=  479  pos_ratio=0.4676  ventanas: pos=   28 neg=   28 tot=   56\n",
      "4_087_1.npz                    | frames=  479  pos_ratio=0.5470  ventanas: pos=   33 neg=   23 tot=   56\n",
      "4_088_1.npz                    | frames=  419  pos_ratio=0.3604  ventanas: pos=   20 neg=   29 tot=   49\n",
      "4_089_1.npz                    | frames= 2249  pos_ratio=0.3304  ventanas: pos=   93 neg=  185 tot=  278\n",
      "4_090_1.npz                    | frames=  299  pos_ratio=0.4615  ventanas: pos=   17 neg=   17 tot=   34\n",
      "4_092_1.npz                    | frames=  299  pos_ratio=0.5786  ventanas: pos=   22 neg=   12 tot=   34\n",
      "4_094_1.npz                    | frames= 1619  pos_ratio=0.8388  ventanas: pos=  170 neg=   29 tot=  199\n",
      "4_095_1.npz                    | frames=  419  pos_ratio=0.3604  ventanas: pos=   19 neg=   30 tot=   49\n",
      "4_096_1.npz                    | frames=  689  pos_ratio=0.5747  ventanas: pos=   49 neg=   34 tot=   83\n",
      "4_098_1.npz                    | frames=  599  pos_ratio=0.6043  ventanas: pos=   45 neg=   26 tot=   71\n",
      "4_100_1.npz                    | frames=  269  pos_ratio=0.5242  ventanas: pos=   18 neg=   12 tot=   30\n",
      "4_101_1.npz                    | frames=  719  pos_ratio=0.5299  ventanas: pos=   47 neg=   39 tot=   86\n",
      "4_107_1.npz                    | frames=  749  pos_ratio=0.2951  ventanas: pos=   28 neg=   62 tot=   90\n",
      "4_108_1.npz                    | frames=  359  pos_ratio=0.4652  ventanas: pos=   21 neg=   20 tot=   41\n",
      "\n",
      "=== RESUMEN GLOBAL ===\n",
      "Frames: tot=267331  pos=47803  pos_ratio=0.1788\n",
      "Ventanas: tot=32858  pos=5985  neg=26873  pos_ratio=0.1821\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ==== CONFIG ====\n",
    "NPZ_DIR  = r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\out_npz\"\n",
    "SEQ_LEN  = 32\n",
    "STRIDE   = 8\n",
    "TAU      = 0.50\n",
    "MIN_RUN  = 3\n",
    "\n",
    "def has_run(x, k=3):\n",
    "    c = 0\n",
    "    for v in x:\n",
    "        c = c + 1 if v == 1 else 0\n",
    "        if c >= k: return True\n",
    "    return False\n",
    "\n",
    "def window_labels_from_frames(labels, T, stride, tau, min_run):\n",
    "    \"\"\"Devuelve y_win (0/1) por ventana sin usar features (solo etiquetas frame a frame).\"\"\"\n",
    "    F = len(labels)\n",
    "    ys = []\n",
    "    for s in range(0, F - T + 1, stride):\n",
    "        seg = labels[s:s+T]\n",
    "        is_pos = (seg.mean() >= tau) and has_run(seg, min_run)\n",
    "        ys.append(1 if is_pos else 0)\n",
    "    return np.array(ys, dtype=np.int64)\n",
    "\n",
    "def main():\n",
    "    paths = sorted(Path(NPZ_DIR).glob(\"*.npz\"))\n",
    "    assert paths, f\"Sin .npz en {NPZ_DIR}\"\n",
    "\n",
    "    tot_frames = 0\n",
    "    tot_pos_frames = 0\n",
    "    tot_win = 0\n",
    "    tot_pos_win = 0\n",
    "\n",
    "    for p in paths:\n",
    "        z = np.load(p, allow_pickle=True)\n",
    "        if \"labels_aligned\" not in z:\n",
    "            print(f\"✗ {p.name} sin 'labels_aligned' → salto\")\n",
    "            continue\n",
    "        y = z[\"labels_aligned\"].astype(np.int64)\n",
    "        pos_ratio = float(y.mean()) if y.size else 0.0\n",
    "\n",
    "        y_win = window_labels_from_frames(y, SEQ_LEN, STRIDE, TAU, MIN_RUN)\n",
    "        n_pos_w = int(y_win.sum())\n",
    "        n_win   = int(len(y_win))\n",
    "        n_neg_w = n_win - n_pos_w\n",
    "\n",
    "        print(f\"{p.name:30s} | frames={len(y):5d}  pos_ratio={pos_ratio:0.4f}  \"\n",
    "              f\"ventanas: pos={n_pos_w:5d} neg={n_neg_w:5d} tot={n_win:5d}\")\n",
    "\n",
    "        tot_frames += len(y)\n",
    "        tot_pos_frames += int(y.sum())\n",
    "        tot_win += n_win\n",
    "        tot_pos_win += n_pos_w\n",
    "\n",
    "    print(\"\\n=== RESUMEN GLOBAL ===\")\n",
    "    if tot_frames:\n",
    "        print(f\"Frames: tot={tot_frames}  pos={tot_pos_frames}  pos_ratio={tot_pos_frames/tot_frames:0.4f}\")\n",
    "    if tot_win:\n",
    "        print(f\"Ventanas: tot={tot_win}  pos={tot_pos_win}  neg={tot_win - tot_pos_win}  \"\n",
    "              f\"pos_ratio={tot_pos_win/tot_win:0.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b999413",
   "metadata": {},
   "source": [
    "EXTRAER NPZ POR VIDEO Y KEYPOINTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308d9a87",
   "metadata": {},
   "source": [
    "////////////////dataset chad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67def093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_npz_cuda_tqdm.py  (versión con conf por joint)\n",
    "import json, cv2, numpy as np, torch\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# =============== CONFIG ===============\n",
    "VIDEOS_DIR = Path(r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\CHAD_VIDEOS\")\n",
    "LABELS_DIR = Path(r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\anomaly_labels\")\n",
    "OUT_DIR    = Path(r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\out_npz\")\n",
    "\n",
    "MODEL      = \"yolo11m-pose.pt\"\n",
    "IMGSZ      = 960\n",
    "CONF_TH    = 0.25\n",
    "IOU_TH     = 0.50\n",
    "TOPK       = 3                    # máx. personas por frame\n",
    "VIDEO_EXTS = {\".mp4\", \".avi\", \".mov\", \".mkv\", \".m4v\"}\n",
    "\n",
    "# =============== HELPERS ===============\n",
    "def _get_xy_conf_per_joint(result):\n",
    "    \"\"\"\n",
    "    Devuelve (xy, c) con shapes:\n",
    "      xy: [P, 17, 2], c: [P, 17]  (confianza por joint)\n",
    "    Usa la confianza del modelo si existe; si no, deriva una máscara 0/1 por joint (validez geométrica).\n",
    "    \"\"\"\n",
    "    kp = result.keypoints\n",
    "    if kp is None or kp.xy is None or kp.xy.shape[0] == 0:\n",
    "        return None, None\n",
    "\n",
    "    xy = kp.xy.detach().cpu().numpy()  # [P,17,2]\n",
    "\n",
    "    # Intenta leer confianza por joint de Ultralytics (distintas versiones exponen .conf o .confidence)\n",
    "    c_attr = None\n",
    "    if hasattr(kp, \"conf\") and (kp.conf is not None):\n",
    "        c_attr = kp.conf\n",
    "    elif hasattr(kp, \"confidence\") and (kp.confidence is not None):\n",
    "        c_attr = kp.confidence\n",
    "\n",
    "    if c_attr is not None:\n",
    "        c = c_attr.detach().cpu().numpy()  # [P,17]\n",
    "        # clamp por seguridad\n",
    "        c = np.clip(c, 0.0, 1.0).astype(np.float32)\n",
    "    else:\n",
    "        # No hay conf por joint: derivar una máscara por joint (0/1) basada en validez de (x,y)\n",
    "        # Nota: >1 px para evitar falsos (0,0), y finitos.\n",
    "        valid = (\n",
    "            np.isfinite(xy[..., 0]) & np.isfinite(xy[..., 1]) &\n",
    "            (xy[..., 0] > 1) & (xy[..., 1] > 1)\n",
    "        )\n",
    "        c = valid.astype(np.float32)  # [P,17]\n",
    "\n",
    "    return xy.astype(np.float32), c.astype(np.float32)\n",
    "\n",
    "# =============== FUNCIONES ===============\n",
    "def process_one(video_path: Path, labels_path: Path, model: YOLO, out_npz: Path, use_cuda: bool):\n",
    "    # Verifica labels\n",
    "    if not labels_path.exists():\n",
    "        tqdm.write(f\"✗ SIN labels → {labels_path.name} no existe. Salto {video_path.name}\")\n",
    "        return False\n",
    "\n",
    "    labels = np.load(str(labels_path))\n",
    "\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        tqdm.write(f\"✗ No se pudo abrir video: {video_path}\")\n",
    "        return False\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    W   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    H   = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    N   = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Validación 1:1\n",
    "    if N != len(labels):\n",
    "        tqdm.write(f\"✗ Descuadre frames/labels en {video_path.name}: frames={N} vs labels={len(labels)}. Salto.\")\n",
    "        cap.release()\n",
    "        return False\n",
    "\n",
    "    # Buffers\n",
    "    kps = np.full((N, TOPK, 17, 3), np.nan, dtype=np.float32)  # (x,y,conf_joint)\n",
    "    per_frame_counts = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "    # Progreso por frames\n",
    "    pbar = tqdm(total=N, desc=f\"{video_path.stem}\", leave=False)\n",
    "\n",
    "    idx = 0\n",
    "    while idx < N:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "\n",
    "        r = model.predict(\n",
    "            frame,\n",
    "            imgsz=IMGSZ,\n",
    "            conf=CONF_TH,\n",
    "            iou=IOU_TH,\n",
    "            verbose=False,\n",
    "            half=use_cuda  # FP16 en GPU\n",
    "        )[0]\n",
    "\n",
    "        xy, c = _get_xy_conf_per_joint(r)\n",
    "        if xy is not None and c is not None and xy.shape[0] > 0:\n",
    "            # Ordenar personas por confianza media (por joint)\n",
    "            order = np.argsort(-c.mean(axis=1))\n",
    "            xy, c = xy[order], c[order]\n",
    "\n",
    "            P = min(xy.shape[0], TOPK)\n",
    "            per_frame_counts[idx] = P\n",
    "\n",
    "            # Ensamblar (x,y,conf_joint) por joint\n",
    "            arr = np.concatenate([xy[:P], c[:P, :, None]], axis=-1)  # [P,17,3]\n",
    "            # Clamp de coords a bordes de imagen (por robustez de validez futura)\n",
    "            arr[..., 0] = np.clip(arr[..., 0], 0, W - 1)\n",
    "            arr[..., 1] = np.clip(arr[..., 1], 0, H - 1)\n",
    "\n",
    "            kps[idx, :P] = arr.astype(np.float32)\n",
    "\n",
    "        idx += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    cap.release()\n",
    "\n",
    "    # Guardado\n",
    "    meta = {\n",
    "        \"video_path\": str(video_path),\n",
    "        \"labels_path\": str(labels_path),\n",
    "        \"fps_video\": float(fps),\n",
    "        \"width\": int(W),\n",
    "        \"height\": int(H),\n",
    "        \"n_video_frames\": int(N),\n",
    "        \"labels_len\": int(len(labels)),\n",
    "        \"imgsz\": int(IMGSZ),\n",
    "        \"model\": MODEL,\n",
    "        \"conf_th\": float(CONF_TH),\n",
    "        \"iou_th\": float(IOU_TH),\n",
    "        \"topk\": int(TOPK)\n",
    "    }\n",
    "\n",
    "    out_npz.parent.mkdir(parents=True, exist_ok=True)\n",
    "    np.savez_compressed(\n",
    "        out_npz,\n",
    "        kps=kps,\n",
    "        per_frame_counts=per_frame_counts,\n",
    "        labels_aligned=labels.astype(labels.dtype),\n",
    "        meta=json.dumps(meta)\n",
    "    )\n",
    "    tqdm.write(f\"✓ {video_path.name} → {out_npz.name} | frames={N} | personas={int(per_frame_counts.sum())}\")\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Modelo una sola vez\n",
    "    model = YOLO(MODEL)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        model.to(\"cuda\")\n",
    "        torch.backends.cudnn.benchmark = True  # tamaño fijo → mejor rendimiento\n",
    "    model.fuse()\n",
    "\n",
    "    videos = sorted([p for p in VIDEOS_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS])\n",
    "    if not videos:\n",
    "        print(f\"✗ No hay videos en {VIDEOS_DIR}\")\n",
    "        return\n",
    "\n",
    "    ok_cnt, fail_cnt = 0, 0\n",
    "    for v in tqdm(videos, desc=\"Videos\", unit=\"vid\"):\n",
    "        stem = v.stem\n",
    "        labels_path = LABELS_DIR / f\"{stem}.npy\"\n",
    "        out_npz = OUT_DIR / f\"{stem}.npz\"\n",
    "\n",
    "        if out_npz.exists():\n",
    "            tqdm.write(f\"- {stem}: ya existe, salto.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            if process_one(v, labels_path, model, out_npz, use_cuda):\n",
    "                ok_cnt += 1\n",
    "            else:\n",
    "                fail_cnt += 1\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"  ✗ error en {stem}: {e}\")\n",
    "            fail_cnt += 1\n",
    "\n",
    "    print(f\"\\nListo. OK={ok_cnt} | Fallos={fail_cnt} | Out={OUT_DIR} | CUDA={'sí' if use_cuda else 'no'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2fb334",
   "metadata": {},
   "source": [
    "////////////////dataset caidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd733d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_npz_fall_yolo11.py\n",
    "import cv2, numpy as np, torch, json\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ========= CONFIG =========\n",
    "VIDEOS_DIR = Path(r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\Dataset_Le21+GMDCSA24\\VideosFall\")\n",
    "ANN_DIR    = Path(r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\Dataset_Le21+GMDCSA24\\Annotation_files\")\n",
    "OUT_DIR    = Path(r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\out_npz_fall\")\n",
    "\n",
    "MODEL      = \"yolo11m-pose.pt\"   # o \"yolo11s-pose.pt\" si priorizas FPS\n",
    "IMGSZ      = 960\n",
    "CONF_TH    = 0.25\n",
    "IOU_TH     = 0.50\n",
    "TOPK       = 3                    # máx. personas por frame\n",
    "VIDEO_EXTS = {\".mp4\", \".avi\", \".mov\", \".mkv\", \".m4v\"}\n",
    "\n",
    "# ========= UTILS =========\n",
    "def read_range_txt(txt_path: Path, n_frames: int):\n",
    "    \"\"\"\n",
    "    Lee 2 líneas: start, end (frames). Soporta 0-based o 1-based.\n",
    "    Devuelve labels [F] con 1 en [start, end], inclusive y recortado.\n",
    "    \"\"\"\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [l.strip() for l in f if l.strip() != \"\"]\n",
    "    if len(lines) < 2:\n",
    "        # sin rango válido => todo 0\n",
    "        return np.zeros(n_frames, dtype=np.uint8)\n",
    "\n",
    "    start_raw = int(float(lines[0]))\n",
    "    end_raw   = int(float(lines[1]))\n",
    "\n",
    "    # Detecta 1-based y corrige si hace falta\n",
    "    start, end = start_raw, end_raw\n",
    "    if end >= n_frames and (end - 1) < n_frames:\n",
    "        start, end = start_raw - 1, end_raw - 1\n",
    "\n",
    "    # Clamp a [0, n_frames-1] y ordena\n",
    "    start = max(0, min(n_frames - 1, start))\n",
    "    end   = max(0, min(n_frames - 1, end))\n",
    "    if end < start:\n",
    "        start, end = end, start\n",
    "\n",
    "    y = np.zeros(n_frames, dtype=np.uint8)\n",
    "    y[start:end + 1] = 1\n",
    "    return y\n",
    "\n",
    "def process_one(video_path: Path, ann_path: Path, model: YOLO, out_npz: Path, use_cuda: bool):\n",
    "    if not ann_path.exists():\n",
    "        tqdm.write(f\"✗ Sin anotación: {ann_path.name} — salto {video_path.name}\")\n",
    "        return False\n",
    "\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        tqdm.write(f\"✗ No se pudo abrir video: {video_path}\")\n",
    "        return False\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    W   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    H   = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    N   = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    labels = read_range_txt(ann_path, N)\n",
    "\n",
    "    # Buffers\n",
    "    kps = np.full((N, TOPK, 17, 3), np.nan, dtype=np.float32)\n",
    "    per_frame_counts = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "    pbar = tqdm(total=N, desc=video_path.stem, leave=False)\n",
    "    idx = 0\n",
    "    while idx < N:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "\n",
    "        r = model.predict(frame, imgsz=IMGSZ, conf=CONF_TH, iou=IOU_TH,\n",
    "                          verbose=False, half=use_cuda)[0]\n",
    "\n",
    "        if r.keypoints is not None and r.keypoints.xy is not None and r.keypoints.xy.shape[0] > 0:\n",
    "            xy = r.keypoints.xy.detach().cpu().numpy()  # (P,17,2)\n",
    "            c  = None\n",
    "            if hasattr(r.keypoints, \"conf\") and r.keypoints.conf is not None:\n",
    "                c = r.keypoints.conf\n",
    "            elif hasattr(r.keypoints, \"confidence\") and r.keypoints.confidence is not None:\n",
    "                c = r.keypoints.confidence\n",
    "            c = c.detach().cpu().numpy() if c is not None else np.ones(xy.shape[:2], dtype=np.float32)\n",
    "\n",
    "            # orden por confianza media de joints\n",
    "            order = np.argsort(-c.mean(axis=1))\n",
    "            xy, c = xy[order], c[order]\n",
    "\n",
    "            P = min(xy.shape[0], TOPK)\n",
    "            per_frame_counts[idx] = P\n",
    "            kps[idx, :P] = np.concatenate([xy[:P], c[:P, :, None]], axis=-1).astype(np.float32)\n",
    "\n",
    "        idx += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    cap.release()\n",
    "\n",
    "    # meta y guardado (mismo formato que CHAD)\n",
    "    meta = {\n",
    "        \"video_path\": str(video_path),\n",
    "        \"labels_path\": str(ann_path),\n",
    "        \"fps_video\": float(fps),\n",
    "        \"width\": int(W),\n",
    "        \"height\": int(H),\n",
    "        \"n_video_frames\": int(N),\n",
    "        \"labels_len\": int(len(labels)),\n",
    "        \"imgsz\": int(IMGSZ),\n",
    "        \"model\": MODEL,\n",
    "        \"conf_th\": float(CONF_TH),\n",
    "        \"iou_th\": float(IOU_TH),\n",
    "        \"topk\": int(TOPK)\n",
    "    }\n",
    "\n",
    "    out_npz.parent.mkdir(parents=True, exist_ok=True)\n",
    "    np.savez_compressed(out_npz,\n",
    "                        kps=kps,\n",
    "                        per_frame_counts=per_frame_counts,\n",
    "                        labels_aligned=labels.astype(labels.dtype),\n",
    "                        meta=json.dumps(meta))\n",
    "    tqdm.write(f\"✓ {video_path.name} → {out_npz.name} | frames={N} | personas={int(per_frame_counts.sum())}\")\n",
    "    return True\n",
    "\n",
    "# ========= MAIN =========\n",
    "def main():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model = YOLO(MODEL)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        model.to(\"cuda\")\n",
    "    model.fuse()\n",
    "\n",
    "    videos = sorted([p for p in VIDEOS_DIR.iterdir() if p.suffix.lower() in VIDEO_EXTS])\n",
    "    if not videos:\n",
    "        print(f\"✗ No hay videos en {VIDEOS_DIR}\")\n",
    "        return\n",
    "\n",
    "    ok_cnt, fail_cnt = 0, 0\n",
    "    for v in tqdm(videos, desc=\"Videos\", unit=\"vid\"):\n",
    "        stem = v.stem\n",
    "        ann_path = ANN_DIR / f\"{stem}.txt\"\n",
    "        out_npz = OUT_DIR / f\"{stem}.npz\"\n",
    "\n",
    "        if out_npz.exists():\n",
    "            tqdm.write(f\"- {stem}: ya existe, salto.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            if process_one(v, ann_path, model, out_npz, use_cuda):\n",
    "                ok_cnt += 1\n",
    "            else:\n",
    "                fail_cnt += 1\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"  ✗ error en {stem}: {e}\")\n",
    "            fail_cnt += 1\n",
    "\n",
    "    print(f\"\\nListo. OK={ok_cnt} | Fallos={fail_cnt} | Out={OUT_DIR} | CUDA={'sí' if use_cuda else 'no'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5bd536",
   "metadata": {},
   "source": [
    "////////////////dataset peleas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "043ff52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11m-pose summary (fused): 134 layers, 20,889,004 parameters, 0 gradients, 71.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:   2%|▏         | 1/64 [00:04<04:34,  4.36s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 2.mp4 → 2.npz | frames=132 | personas=393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:   3%|▎         | 2/64 [00:06<03:16,  3.17s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 3.mp4 → 3.npz | frames=93 | personas=273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:   5%|▍         | 3/64 [00:20<08:05,  7.97s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Robbery070_x264.mp4 → Robbery070_x264.npz | frames=591 | personas=1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:   6%|▋         | 4/64 [00:26<07:16,  7.28s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ v025_converted.avi → v025_converted.npz | frames=311 | personas=880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:   8%|▊         | 5/64 [00:33<07:06,  7.23s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ v068_converted.avi → v068_converted.npz | frames=327 | personas=951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:   9%|▉         | 6/64 [00:40<06:48,  7.04s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ v075_converted.avi → v075_converted.npz | frames=324 | personas=923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  11%|█         | 7/64 [00:46<06:26,  6.79s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ v081_converted.avi → v081_converted.npz | frames=321 | personas=664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  12%|█▎        | 8/64 [00:48<04:58,  5.33s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_1.mp4 → V_1.npz | frames=103 | personas=166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  14%|█▍        | 9/64 [00:53<04:48,  5.25s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_21.mp4 → V_21.npz | frames=180 | personas=440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  16%|█▌        | 10/64 [00:56<04:04,  4.52s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_23.mp4 → V_23.npz | frames=126 | personas=262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  17%|█▋        | 11/64 [01:00<03:45,  4.25s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_26.mp4 → V_26.npz | frames=126 | personas=283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  19%|█▉        | 12/64 [01:03<03:26,  3.98s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_290.mp4 → V_290.npz | frames=141 | personas=422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  20%|██        | 13/64 [01:06<03:09,  3.71s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_297.mp4 → V_297.npz | frames=141 | personas=325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  22%|██▏       | 14/64 [01:11<03:15,  3.92s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_3.mp4 → V_3.npz | frames=174 | personas=348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  23%|██▎       | 15/64 [01:15<03:20,  4.09s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_300.mp4 → V_300.npz | frames=195 | personas=585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  25%|██▌       | 16/64 [01:19<03:06,  3.88s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_320.mp4 → V_320.npz | frames=162 | personas=422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  27%|██▋       | 17/64 [01:22<02:52,  3.66s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_321.mp4 → V_321.npz | frames=132 | personas=396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  28%|██▊       | 18/64 [01:25<02:43,  3.55s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_4.mp4 → V_4.npz | frames=151 | personas=302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  30%|██▉       | 19/64 [01:28<02:33,  3.41s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_413.mp4 → V_413.npz | frames=117 | personas=190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  31%|███▏      | 20/64 [01:32<02:39,  3.62s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_421.mp4 → V_421.npz | frames=159 | personas=477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  33%|███▎      | 21/64 [01:35<02:25,  3.38s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_452.mp4 → V_452.npz | frames=141 | personas=280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  34%|███▍      | 22/64 [01:38<02:10,  3.10s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_5.mp4 → V_5.npz | frames=114 | personas=223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  36%|███▌      | 23/64 [01:41<02:11,  3.21s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_58.mp4 → V_58.npz | frames=117 | personas=351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  38%|███▊      | 24/64 [01:44<02:06,  3.17s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_62.mp4 → V_62.npz | frames=114 | personas=337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  39%|███▉      | 25/64 [01:48<02:12,  3.40s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_629.mp4 → V_629.npz | frames=180 | personas=540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  41%|████      | 26/64 [01:51<02:03,  3.26s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_63.mp4 → V_63.npz | frames=129 | personas=387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  42%|████▏     | 27/64 [01:54<01:59,  3.24s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_630.mp4 → V_630.npz | frames=150 | personas=450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  44%|████▍     | 28/64 [01:58<02:05,  3.50s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_638.mp4 → V_638.npz | frames=150 | personas=431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  45%|████▌     | 29/64 [02:01<01:56,  3.32s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_70.mp4 → V_70.npz | frames=147 | personas=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  47%|████▋     | 30/64 [02:04<01:50,  3.25s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_71.mp4 → V_71.npz | frames=150 | personas=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  48%|████▊     | 31/64 [02:07<01:40,  3.06s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_72.mp4 → V_72.npz | frames=150 | personas=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  50%|█████     | 32/64 [02:10<01:34,  2.96s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_743.mp4 → V_743.npz | frames=141 | personas=317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  52%|█████▏    | 33/64 [02:12<01:28,  2.86s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_75.mp4 → V_75.npz | frames=150 | personas=173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  53%|█████▎    | 34/64 [02:15<01:26,  2.88s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_752.mp4 → V_752.npz | frames=126 | personas=365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  55%|█████▍    | 35/64 [02:18<01:21,  2.82s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_755.mp4 → V_755.npz | frames=126 | personas=348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  56%|█████▋    | 36/64 [02:20<01:16,  2.73s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_761.mp4 → V_761.npz | frames=126 | personas=304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  58%|█████▊    | 37/64 [02:23<01:14,  2.77s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_764.mp4 → V_764.npz | frames=123 | personas=369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  59%|█████▉    | 38/64 [02:26<01:12,  2.78s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_765.mp4 → V_765.npz | frames=129 | personas=373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  61%|██████    | 39/64 [02:29<01:07,  2.70s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_84.mp4 → V_84.npz | frames=150 | personas=162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  62%|██████▎   | 40/64 [02:31<01:03,  2.64s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_85.mp4 → V_85.npz | frames=150 | personas=96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  64%|██████▍   | 41/64 [02:34<01:00,  2.63s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_86.mp4 → V_86.npz | frames=150 | personas=179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  66%|██████▌   | 42/64 [02:37<01:02,  2.85s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ V_957.mp4 → V_957.npz | frames=159 | personas=243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  67%|██████▋   | 43/64 [02:40<00:59,  2.84s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Vídeo sin título ‐ Hecho con Clipchamp.mp4 → Vídeo sin título ‐ Hecho con Clipchamp.npz | frames=138 | personas=209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  69%|██████▉   | 44/64 [02:43<00:55,  2.79s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ n015_converted.avi → n015_converted.npz | frames=133 | personas=329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  70%|███████   | 45/64 [02:45<00:52,  2.76s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ n142_converted.avi → n142_converted.npz | frames=147 | personas=225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  72%|███████▏  | 46/64 [02:46<00:37,  2.11s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ n154_converted.avi → n154_converted.npz | frames=31 | personas=81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  73%|███████▎  | 47/64 [02:46<00:28,  1.66s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ n155_converted.avi → n155_converted.npz | frames=31 | personas=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  75%|███████▌  | 48/64 [02:49<00:31,  1.95s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ n156_converted.avi → n156_converted.npz | frames=132 | personas=390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  77%|███████▋  | 49/64 [02:51<00:31,  2.08s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ n157_converted.avi → n157_converted.npz | frames=119 | personas=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  78%|███████▊  | 50/64 [02:54<00:31,  2.26s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ n190_converted.avi → n190_converted.npz | frames=125 | personas=375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  80%|███████▉  | 51/64 [02:57<00:31,  2.41s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ n191_converted.avi → n191_converted.npz | frames=126 | personas=378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  81%|████████▏ | 52/64 [03:10<01:07,  5.61s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Normal_Videos_100_x264.mp4 → Normal_Videos_100_x264.npz | frames=627 | personas=1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  83%|████████▎ | 53/64 [03:20<01:16,  6.97s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Normal_Videos_129_x264.mp4 → Normal_Videos_129_x264.npz | frames=467 | personas=1401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  84%|████████▍ | 54/64 [03:25<01:02,  6.24s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Normal_Videos_345_x264.mp4 → Normal_Videos_345_x264.npz | frames=209 | personas=627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  86%|████████▌ | 55/64 [03:46<01:36, 10.72s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Normal_Videos_360_x264.mp4 → Normal_Videos_360_x264.npz | frames=984 | personas=2892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  88%|████████▊ | 56/64 [03:47<01:03,  7.91s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ NV_1.mp4 → NV_1.npz | frames=66 | personas=121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  89%|████████▉ | 57/64 [03:50<00:43,  6.27s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ t_n008_converted.avi → t_n008_converted.npz | frames=119 | personas=356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  91%|█████████ | 58/64 [03:52<00:31,  5.18s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ t_n009_converted.avi → t_n009_converted.npz | frames=129 | personas=387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  92%|█████████▏| 59/64 [03:55<00:22,  4.41s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ t_n010_converted.avi → t_n010_converted.npz | frames=138 | personas=376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  94%|█████████▍| 60/64 [03:57<00:15,  3.82s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ t_n012_converted.avi → t_n012_converted.npz | frames=131 | personas=278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  95%|█████████▌| 61/64 [04:00<00:10,  3.52s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ t_n013_converted.avi → t_n013_converted.npz | frames=139 | personas=417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  97%|█████████▋| 62/64 [04:03<00:06,  3.24s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ t_n014_converted.avi → t_n014_converted.npz | frames=124 | personas=368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos:  98%|█████████▊| 63/64 [04:05<00:03,  3.08s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ t_n015_converted.avi → t_n015_converted.npz | frames=134 | personas=401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos: 100%|██████████| 64/64 [04:07<00:00,  3.87s/vid]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ t_n016_converted.avi → t_n016_converted.npz | frames=76 | personas=228\n",
      "\n",
      "Listo. OK=64 | Fallos=0 | Out=C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\out_npz_video | CUDA=sí\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# batch_npz_videolevel_mix.py\n",
    "import json, cv2, numpy as np, torch\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ====== CONFIG ======\n",
    "ANOMALY_DIR = Path(r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\DATASETS_COMBINADOS\\anomalia\")   # etiqueta dura = 1\n",
    "NORMAL_DIR  = Path(r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\DATASETS_COMBINADOS\\no_anomalia\")     # etiqueta dura = 0\n",
    "\n",
    "# Puedes añadir más carpetas (dir, label) aquí:\n",
    "SOURCES = [\n",
    "    (ANOMALY_DIR, 1),\n",
    "    (NORMAL_DIR,  0),\n",
    "]\n",
    "\n",
    "OUT_DIR   = Path(r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\out_npz_video\")\n",
    "MODEL     = \"yolo11m-pose.pt\"     \n",
    "IMGSZ      = 960\n",
    "CONF_TH    = 0.25\n",
    "IOU_TH     = 0.50\n",
    "TOPK       = 3                    # máx. personas por frame\n",
    "VIDEO_EXT = {\".mp4\", \".avi\", \".mov\", \".mkv\", \".m4v\"}\n",
    "RECURSIVE = True                  # si True, usa rglob para recorrer subcarpetas\n",
    "TRIM_BORDERS_POS = 5             # recorta 15 frames al inicio/fin SOLO si label=1 (clips duros)\n",
    "MIN_FRAMES = 8                    # descarta videos muy cortos\n",
    "\n",
    "# ====== HELPERS ======\n",
    "def _get_xy_conf_per_joint(result):\n",
    "    \"\"\"\n",
    "    Devuelve:\n",
    "      xy: [P,17,2]  (float32)\n",
    "      c : [P,17]    (float32, confianza por joint en [0,1])\n",
    "    Si la versión de Ultralytics no trae conf por joint, se crea máscara 0/1 por validez geométrica.\n",
    "    \"\"\"\n",
    "    kp = result.keypoints\n",
    "    if kp is None or kp.xy is None or kp.xy.shape[0] == 0:\n",
    "        return None, None\n",
    "\n",
    "    xy = kp.xy.detach().cpu().numpy().astype(np.float32)  # [P,17,2]\n",
    "\n",
    "    c_attr = None\n",
    "    if hasattr(kp, \"conf\") and kp.conf is not None:\n",
    "        c_attr = kp.conf\n",
    "    elif hasattr(kp, \"confidence\") and kp.confidence is not None:\n",
    "        c_attr = kp.confidence\n",
    "\n",
    "    if c_attr is not None:\n",
    "        c = c_attr.detach().cpu().numpy().astype(np.float32)  # [P,17]\n",
    "        c = np.clip(c, 0.0, 1.0)\n",
    "    else:\n",
    "        valid = (\n",
    "            np.isfinite(xy[..., 0]) & np.isfinite(xy[..., 1]) &\n",
    "            (xy[..., 0] > 1) & (xy[..., 1] > 1)\n",
    "        )\n",
    "        c = valid.astype(np.float32)  # [P,17]\n",
    "\n",
    "    return xy, c\n",
    "\n",
    "def _iter_videos(d: Path):\n",
    "    if not d.exists():\n",
    "        tqdm.write(f\"Carpeta no existe: {d}\")\n",
    "        return []\n",
    "    if RECURSIVE:\n",
    "        return [p for p in d.rglob(\"*\") if p.suffix.lower() in VIDEO_EXT]\n",
    "    else:\n",
    "        return [p for p in d.iterdir() if p.suffix.lower() in VIDEO_EXT]\n",
    "\n",
    "# ====== CORE ======\n",
    "def process_one(video_path: Path, model: YOLO, out_npz: Path, label_value: int, use_cuda: bool) -> bool:\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        tqdm.write(f\"✗ No abre: {video_path.name}\")\n",
    "        return False\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    W   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    H   = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    N   = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    if N < MIN_FRAMES:\n",
    "        tqdm.write(f\"- {video_path.name}: muy corto ({N} frames). Salto.\")\n",
    "        cap.release()\n",
    "        return False\n",
    "\n",
    "    # buffers\n",
    "    kps = np.full((N, TOPK, 17, 3), np.nan, dtype=np.float32)  # (x,y,conf_joint)\n",
    "    per_frame_counts = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "    # etiqueta dura por frame (con recorte en positivos para evitar bordes ruidosos)\n",
    "    labels_aligned = np.full(N, int(label_value), dtype=np.int8)\n",
    "    if label_value == 1 and TRIM_BORDERS_POS > 0 and N > 2 * TRIM_BORDERS_POS:\n",
    "        labels_aligned[:TRIM_BORDERS_POS] = 0\n",
    "        labels_aligned[-TRIM_BORDERS_POS:] = 0\n",
    "\n",
    "    pbar = tqdm(total=N, desc=video_path.stem, leave=False)\n",
    "    idx = 0\n",
    "    while idx < N:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "\n",
    "        r = model.predict(frame, imgsz=IMGSZ, conf=CONF_TH, iou=IOU_TH,\n",
    "                          verbose=False, half=use_cuda)[0]\n",
    "\n",
    "        xy, c = _get_xy_conf_per_joint(r)\n",
    "        if xy is not None and c is not None and xy.shape[0] > 0:\n",
    "            # Ordenar personas por confianza media en joints\n",
    "            order = np.argsort(-c.mean(axis=1))\n",
    "            xy, c = xy[order], c[order]\n",
    "\n",
    "            P = min(xy.shape[0], TOPK)\n",
    "            per_frame_counts[idx] = P\n",
    "\n",
    "            arr = np.concatenate([xy[:P], c[:P, :, None]], axis=-1).astype(np.float32)  # [P,17,3]\n",
    "            # clamp coords\n",
    "            arr[..., 0] = np.clip(arr[..., 0], 0, W - 1)\n",
    "            arr[..., 1] = np.clip(arr[..., 1], 0, H - 1)\n",
    "\n",
    "            kps[idx, :P] = arr\n",
    "\n",
    "        idx += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    cap.release()\n",
    "\n",
    "    meta = {\n",
    "        \"video_path\": str(video_path),\n",
    "        \"labels_path\": \"video_level_label\",\n",
    "        \"fps_video\": float(fps),\n",
    "        \"width\": int(W),\n",
    "        \"height\": int(H),\n",
    "        \"n_video_frames\": int(N),\n",
    "        \"labels_len\": int(N),\n",
    "        \"imgsz\": int(IMGSZ),\n",
    "        \"model\": MODEL,\n",
    "        \"conf_th\": float(CONF_TH),\n",
    "        \"iou_th\": float(IOU_TH),\n",
    "        \"topk\": int(TOPK),\n",
    "        \"video_level_label\": int(label_value)\n",
    "    }\n",
    "\n",
    "    out_npz.parent.mkdir(parents=True, exist_ok=True)\n",
    "    np.savez_compressed(\n",
    "        out_npz,\n",
    "        kps=kps,\n",
    "        per_frame_counts=per_frame_counts,\n",
    "        labels_aligned=labels_aligned,\n",
    "        meta=json.dumps(meta)\n",
    "    )\n",
    "    tqdm.write(f\"✓ {video_path.name} → {out_npz.name} | frames={N} | personas={int(per_frame_counts.sum())}\")\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # modelo una sola vez\n",
    "    model = YOLO(MODEL)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        model.to(\"cuda\")\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    model.fuse()\n",
    "\n",
    "    vids = []\n",
    "    for d, y in SOURCES:\n",
    "        vids_dir = _iter_videos(d)\n",
    "        vids.extend([(p, y) for p in sorted(vids_dir)])\n",
    "\n",
    "    if not vids:\n",
    "        print(\"✗ No se encontraron videos.\")\n",
    "        return\n",
    "\n",
    "    ok, fail = 0, 0\n",
    "    for vpath, ylab in tqdm(vids, desc=\"Videos\", unit=\"vid\"):\n",
    "        out_npz = OUT_DIR / f\"{vpath.stem}.npz\"\n",
    "        if out_npz.exists():\n",
    "            tqdm.write(f\"- {vpath.stem}: ya existe, salto.\")\n",
    "            continue\n",
    "        try:\n",
    "            if process_one(vpath, model, out_npz, ylab, use_cuda):\n",
    "                ok += 1\n",
    "            else:\n",
    "                fail += 1\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"  ✗ error en {vpath.stem}: {e}\")\n",
    "            fail += 1\n",
    "\n",
    "    print(f\"\\nListo. OK={ok} | Fallos={fail} | Out={OUT_DIR} | CUDA={'sí' if use_cuda else 'no'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732736c4",
   "metadata": {},
   "source": [
    "ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7545484c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ventanas: 9336 | Pos=2936 (0.314)\n",
      "Splits → train=6715  val=1112  test=1509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\venv\\Lib\\site-packages\\keras\\src\\layers\\layer.py:970: UserWarning: Layer 'conv1d_6' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masking_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,288</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m51\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masking_3 (\u001b[38;5;33mMasking\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m51\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m9,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m12,288\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,465</span> (275.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m70,465\u001b[0m (275.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,209</span> (274.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m70,209\u001b[0m (274.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - acc: 0.6721 - auc: 0.6123 - loss: 0.2349 - pr_auc: 0.3984 - precision: 0.4520 - recall: 0.1206 - val_acc: 0.7383 - val_auc: 0.5551 - val_loss: 0.2210 - val_pr_auc: 0.2747 - val_precision: 0.2857 - val_recall: 0.0599 - learning_rate: 3.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - acc: 0.7029 - auc: 0.6917 - loss: 0.2231 - pr_auc: 0.4959 - precision: 0.5843 - recall: 0.2455 - val_acc: 0.7311 - val_auc: 0.5162 - val_loss: 0.2357 - val_pr_auc: 0.2451 - val_precision: 0.2576 - val_recall: 0.0637 - learning_rate: 3.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - acc: 0.7239 - auc: 0.7295 - loss: 0.2149 - pr_auc: 0.5471 - precision: 0.6076 - recall: 0.3852 - val_acc: 0.7068 - val_auc: 0.4649 - val_loss: 0.2603 - val_pr_auc: 0.2272 - val_precision: 0.2243 - val_recall: 0.0899 - learning_rate: 3.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - acc: 0.7375 - auc: 0.7568 - loss: 0.2080 - pr_auc: 0.5880 - precision: 0.6253 - recall: 0.4462 - val_acc: 0.7149 - val_auc: 0.5181 - val_loss: 0.2612 - val_pr_auc: 0.2502 - val_precision: 0.2596 - val_recall: 0.1011 - learning_rate: 3.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - acc: 0.7445 - auc: 0.7682 - loss: 0.2049 - pr_auc: 0.6019 - precision: 0.6341 - recall: 0.4746 - val_acc: 0.7212 - val_auc: 0.6025 - val_loss: 0.2423 - val_pr_auc: 0.3021 - val_precision: 0.3130 - val_recall: 0.1348 - learning_rate: 3.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - acc: 0.7555 - auc: 0.7842 - loss: 0.2000 - pr_auc: 0.6240 - precision: 0.6539 - recall: 0.4998 - val_acc: 0.7338 - val_auc: 0.5646 - val_loss: 0.2555 - val_pr_auc: 0.2844 - val_precision: 0.3739 - val_recall: 0.1610 - learning_rate: 3.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - acc: 0.7641 - auc: 0.7927 - loss: 0.1969 - pr_auc: 0.6457 - precision: 0.6687 - recall: 0.5198 - val_acc: 0.6906 - val_auc: 0.6065 - val_loss: 0.2573 - val_pr_auc: 0.2975 - val_precision: 0.3402 - val_recall: 0.3071 - learning_rate: 3.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - acc: 0.7668 - auc: 0.8059 - loss: 0.1929 - pr_auc: 0.6546 - precision: 0.6618 - recall: 0.5533 - val_acc: 0.6996 - val_auc: 0.6282 - val_loss: 0.2459 - val_pr_auc: 0.3149 - val_precision: 0.3816 - val_recall: 0.4045 - learning_rate: 3.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - acc: 0.7756 - auc: 0.8106 - loss: 0.1910 - pr_auc: 0.6627 - precision: 0.6806 - recall: 0.5617 - val_acc: 0.6772 - val_auc: 0.5810 - val_loss: 0.2705 - val_pr_auc: 0.2804 - val_precision: 0.2946 - val_recall: 0.2472 - learning_rate: 3.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - acc: 0.7789 - auc: 0.8190 - loss: 0.1879 - pr_auc: 0.6780 - precision: 0.6849 - recall: 0.5710 - val_acc: 0.6817 - val_auc: 0.5937 - val_loss: 0.2708 - val_pr_auc: 0.2913 - val_precision: 0.3294 - val_recall: 0.3146 - learning_rate: 3.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - acc: 0.7888 - auc: 0.8290 - loss: 0.1837 - pr_auc: 0.6969 - precision: 0.7103 - recall: 0.5734 - val_acc: 0.6942 - val_auc: 0.6174 - val_loss: 0.2670 - val_pr_auc: 0.3056 - val_precision: 0.3348 - val_recall: 0.2772 - learning_rate: 3.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - acc: 0.7832 - auc: 0.8254 - loss: 0.1851 - pr_auc: 0.6909 - precision: 0.7046 - recall: 0.5543 - val_acc: 0.7329 - val_auc: 0.6627 - val_loss: 0.2374 - val_pr_auc: 0.3655 - val_precision: 0.4324 - val_recall: 0.3596 - learning_rate: 3.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - acc: 0.7875 - auc: 0.8326 - loss: 0.1823 - pr_auc: 0.7028 - precision: 0.7013 - recall: 0.5841 - val_acc: 0.6906 - val_auc: 0.6128 - val_loss: 0.2732 - val_pr_auc: 0.3103 - val_precision: 0.3490 - val_recall: 0.3333 - learning_rate: 3.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - acc: 0.7918 - auc: 0.8402 - loss: 0.1793 - pr_auc: 0.7122 - precision: 0.7098 - recall: 0.5901 - val_acc: 0.7347 - val_auc: 0.6647 - val_loss: 0.2504 - val_pr_auc: 0.3587 - val_precision: 0.4474 - val_recall: 0.4457 - learning_rate: 3.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - acc: 0.7978 - auc: 0.8417 - loss: 0.1781 - pr_auc: 0.7230 - precision: 0.7195 - recall: 0.6022 - val_acc: 0.7275 - val_auc: 0.6803 - val_loss: 0.2476 - val_pr_auc: 0.3644 - val_precision: 0.4297 - val_recall: 0.4120 - learning_rate: 3.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - acc: 0.7966 - auc: 0.8436 - loss: 0.1778 - pr_auc: 0.7121 - precision: 0.7188 - recall: 0.5976 - val_acc: 0.7446 - val_auc: 0.7085 - val_loss: 0.2250 - val_pr_auc: 0.4113 - val_precision: 0.4615 - val_recall: 0.3820 - learning_rate: 3.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - acc: 0.8037 - auc: 0.8561 - loss: 0.1721 - pr_auc: 0.7403 - precision: 0.7294 - recall: 0.6139 - val_acc: 0.7374 - val_auc: 0.6830 - val_loss: 0.2501 - val_pr_auc: 0.3763 - val_precision: 0.4459 - val_recall: 0.3858 - learning_rate: 3.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - acc: 0.8067 - auc: 0.8541 - loss: 0.1726 - pr_auc: 0.7353 - precision: 0.7375 - recall: 0.6139 - val_acc: 0.7176 - val_auc: 0.6552 - val_loss: 0.2666 - val_pr_auc: 0.3450 - val_precision: 0.4078 - val_recall: 0.3895 - learning_rate: 3.0000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - acc: 0.8086 - auc: 0.8615 - loss: 0.1696 - pr_auc: 0.7490 - precision: 0.7340 - recall: 0.6297 - val_acc: 0.7392 - val_auc: 0.6747 - val_loss: 0.2587 - val_pr_auc: 0.3743 - val_precision: 0.4579 - val_recall: 0.4682 - learning_rate: 3.0000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m53/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.8136 - auc: 0.8635 - loss: 0.1677 - pr_auc: 0.7496 - precision: 0.7382 - recall: 0.6336\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - acc: 0.8095 - auc: 0.8613 - loss: 0.1692 - pr_auc: 0.7508 - precision: 0.7393 - recall: 0.6246 - val_acc: 0.6978 - val_auc: 0.6350 - val_loss: 0.2935 - val_pr_auc: 0.3254 - val_precision: 0.3745 - val_recall: 0.3858 - learning_rate: 3.0000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - acc: 0.8116 - auc: 0.8671 - loss: 0.1671 - pr_auc: 0.7478 - precision: 0.7412 - recall: 0.6311 - val_acc: 0.7248 - val_auc: 0.6755 - val_loss: 0.2613 - val_pr_auc: 0.3748 - val_precision: 0.4093 - val_recall: 0.3296 - learning_rate: 1.5000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - acc: 0.8134 - auc: 0.8738 - loss: 0.1636 - pr_auc: 0.7661 - precision: 0.7427 - recall: 0.6372 - val_acc: 0.7257 - val_auc: 0.6688 - val_loss: 0.2697 - val_pr_auc: 0.3728 - val_precision: 0.4040 - val_recall: 0.2996 - learning_rate: 1.5000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - acc: 0.8164 - auc: 0.8745 - loss: 0.1631 - pr_auc: 0.7601 - precision: 0.7473 - recall: 0.6432 - val_acc: 0.7356 - val_auc: 0.6701 - val_loss: 0.2672 - val_pr_auc: 0.3776 - val_precision: 0.4416 - val_recall: 0.3820 - learning_rate: 1.5000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.8297 - auc: 0.8797 - loss: 0.1597 - pr_auc: 0.7755 - precision: 0.7644 - recall: 0.6655\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - acc: 0.8261 - auc: 0.8757 - loss: 0.1624 - pr_auc: 0.7715 - precision: 0.7645 - recall: 0.6591 - val_acc: 0.7320 - val_auc: 0.6850 - val_loss: 0.2620 - val_pr_auc: 0.3836 - val_precision: 0.4346 - val_recall: 0.3858 - learning_rate: 1.5000e-04\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "\n",
      "Mejor umbral (val, F1): t=0.40  F1=0.556\n",
      "\n",
      "=== TEST ===\n",
      "ROC-AUC : 0.6099795424813768\n",
      "PR-AUC  : 0.44404016424193904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7318    0.6717    0.7005       987\n",
      "           1     0.4627    0.5345    0.4960       522\n",
      "\n",
      "    accuracy                         0.6243      1509\n",
      "   macro avg     0.5972    0.6031    0.5982      1509\n",
      "weighted avg     0.6387    0.6243    0.6297      1509\n",
      "\n",
      "[[663 324]\n",
      " [243 279]]\n",
      "\n",
      "Guardado modelo: models_mix\\mix_cnn_lstm_T32_F51.keras\n",
      "Guardado norm stats: models_mix\\mix_cnn_lstm_T32_F51_norm_stats.npz\n",
      "Guardado umbral óptimo: models_mix\\mix_cnn_lstm_T32_F51_threshold.json\n"
     ]
    }
   ],
   "source": [
    "# mix_train_cnnlstm_focalloss_v2.py\n",
    "import os, json, numpy as np, tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, regularizers\n",
    "from tensorflow.keras.losses import BinaryFocalCrossentropy\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, roc_auc_score, average_precision_score\n",
    "\n",
    "# =======================\n",
    "# CONFIG\n",
    "# =======================\n",
    "NPZ_DIRS = [\n",
    "    r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\out_npz\",          # CHAD (frame-level)\n",
    "    r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\out_npz_fall\",     # FALL (rango/frame-level)\n",
    "    r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\out_npz_video\"     # video-level (clips duros)\n",
    "]\n",
    "\n",
    "MODEL_KIND   = \"cnn_lstm\"   # \"lstm\" o \"cnn_lstm\"\n",
    "SEQ_LEN      = 32\n",
    "STRIDE       =12\n",
    "\n",
    "# Limpieza/etiquetado\n",
    "MIN_VIS_FRAC = 0.30   \n",
    "CONF_MIN     = 0.10   \n",
    "TRIM_BORDERS = 0     \n",
    "\n",
    "VAL_RATIO    = 0.15   # split por VIDEO y por DOMINIO (sin solape)\n",
    "TEST_RATIO   = 0.15\n",
    "EPOCHS       = 30\n",
    "BATCH_SIZE   = 124\n",
    "SEED         = 42\n",
    "\n",
    "MODEL_DIR = Path(\"./models_mix\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# =======================\n",
    "# HELPERS\n",
    "# =======================\n",
    "def load_meta(z):\n",
    "    meta_raw = z[\"meta\"]\n",
    "    try:\n",
    "        return json.loads(meta_raw.item() if hasattr(meta_raw, \"item\") else meta_raw)\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "def pool_frame_to_51(kps_f, W, H):\n",
    "    \"\"\"\n",
    "    kps_f: (K,17,3) -> (51,) normalizado. Toma por joint la persona con mayor conf.\n",
    "    \"\"\"\n",
    "    out = np.zeros((17, 3), dtype=np.float32)\n",
    "    conf_j = kps_f[..., 2]\n",
    "    conf_j = np.nan_to_num(conf_j, nan=0.0)\n",
    "    for j in range(17):\n",
    "        idx = np.argmax(conf_j[:, j]) if conf_j.shape[0] else None\n",
    "        if idx is not None and conf_j[idx, j] > 0:\n",
    "            x, y, c = kps_f[idx, j, :]\n",
    "            if np.isfinite(x) and np.isfinite(y):\n",
    "                out[j, 0] = np.clip(x / max(W, 1), 0.0, 1.0)\n",
    "                out[j, 1] = np.clip(y / max(H, 1), 0.0, 1.0)\n",
    "                out[j, 2] = float(np.clip(c, 0.0, 1.0))\n",
    "    return out.reshape(-1)\n",
    "\n",
    "def frame_visible(kps_f, conf_min=CONF_MIN):\n",
    "    conf = kps_f[..., 2]\n",
    "    conf = np.nan_to_num(conf, nan=0.0)\n",
    "    return bool((conf >= conf_min).any())\n",
    "\n",
    "def video_to_windows(npz_path: Path):\n",
    "    \"\"\"\n",
    "    Devuelve:\n",
    "      Xw: (Nw, SEQ_LEN, 51)\n",
    "      Yw: (Nw,)  -> etiqueta del ÚLTIMO frame (tiempo real)\n",
    "      vid_id: nombre del video (string)\n",
    "      domain: dominio (carpeta padre inmediata del .npz)\n",
    "    Filtros:\n",
    "      - Recorte de bordes para clips duros\n",
    "      - Rechazo de ventanas con visibilidad < MIN_VIS_FRAC\n",
    "    \"\"\"\n",
    "    z = np.load(npz_path, allow_pickle=True)\n",
    "    if not {\"kps\", \"labels_aligned\", \"meta\"}.issubset(z.files):\n",
    "        return np.zeros((0, SEQ_LEN, 51), np.float32), np.zeros((0,), np.int64), npz_path.name, npz_path.parent.name\n",
    "\n",
    "    kps  = z[\"kps\"]                               # (F,K,17,3)\n",
    "    y    = z[\"labels_aligned\"].astype(np.int64)   # (F,)\n",
    "    meta = load_meta(z)\n",
    "    W, H = int(meta.get(\"width\", 1920)), int(meta.get(\"height\", 1080))\n",
    "    F    = kps.shape[0]\n",
    "\n",
    "    if F != len(y) or F < SEQ_LEN:\n",
    "        return np.zeros((0, SEQ_LEN, 51), np.float32), np.zeros((0,), np.int64), npz_path.name, npz_path.parent.name\n",
    "\n",
    "    # Trim para video-level positivos (clips duros)\n",
    "    if meta.get(\"video_level_label\", 0) == 1 and TRIM_BORDERS > 0 and F > 2 * TRIM_BORDERS:\n",
    "        y = y.copy()\n",
    "        y[:TRIM_BORDERS] = 0\n",
    "        y[-TRIM_BORDERS:] = 0\n",
    "\n",
    "    # Features y visibilidad por frame\n",
    "    feats = np.zeros((F, 51), dtype=np.float32)\n",
    "    vis   = np.zeros(F, dtype=np.float32)\n",
    "    for t in range(F):\n",
    "        feats[t] = pool_frame_to_51(kps[t], W, H)\n",
    "        vis[t]   = 1.0 if frame_visible(kps[t], conf_min=CONF_MIN) else 0.0\n",
    "\n",
    "    # Ventanas con STRIDE, target = último frame\n",
    "    Xw, Yw = [], []\n",
    "    for s in range(0, F - SEQ_LEN + 1, STRIDE):\n",
    "        e = s + SEQ_LEN\n",
    "        if vis[s:e].mean() < MIN_VIS_FRAC:\n",
    "            continue\n",
    "        Xw.append(feats[s:e])\n",
    "        Yw.append(int(y[e - 1]))  # tiempo real\n",
    "\n",
    "    Xw = np.stack(Xw, 0) if Xw else np.zeros((0, SEQ_LEN, 51), np.float32)\n",
    "    Yw = np.array(Yw, dtype=np.int64) if len(Yw) else np.zeros((0,), np.int64)\n",
    "    return Xw, Yw, npz_path.name, npz_path.parent.name\n",
    "\n",
    "def standardize_fit_apply(Xtr, Xva, Xte):\n",
    "    Ntr, T, F = Xtr.shape\n",
    "    mu = Xtr.reshape(-1, F).mean(axis=0, keepdims=True)\n",
    "    sd = Xtr.reshape(-1, F).std(axis=0, keepdims=True) + 1e-6\n",
    "    def norm(X):\n",
    "        N = X.shape[0]\n",
    "        return ((X.reshape(-1, F) - mu) / sd).reshape(N, T, F).astype(\"float32\")\n",
    "    return norm(Xtr), norm(Xva), norm(Xte), {\"mean\": mu.astype(\"float32\"), \"std\": sd.astype(\"float32\")}\n",
    "\n",
    "def stratified_split_by_domain(vid_ids, domains, val_ratio, test_ratio, seed=SEED):\n",
    "    \"\"\"\n",
    "    Split por VIDEO estratificado por dominio (carpeta padre).\n",
    "    Retorna conjuntos de vid_ids: train_ids, val_ids, test_ids\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    vid_ids = np.array(vid_ids)\n",
    "    domains = np.array(domains)\n",
    "    train_ids, val_ids, test_ids = set(), set(), set()\n",
    "    for d in np.unique(domains):\n",
    "        mask = (domains == d)\n",
    "        vids_d = np.unique(vid_ids[mask])\n",
    "        vids_d = vids_d.copy()\n",
    "        rng.shuffle(vids_d)\n",
    "        n = len(vids_d)\n",
    "        n_test = int(round(n * test_ratio))\n",
    "        n_val  = int(round(n * val_ratio))\n",
    "        test_ids.update(vids_d[:n_test])\n",
    "        val_ids.update(vids_d[n_test:n_test + n_val])\n",
    "        train_ids.update(vids_d[n_test + n_val:])\n",
    "    return train_ids, val_ids, test_ids\n",
    "\n",
    "# =======================\n",
    "# MODELOS\n",
    "# =======================\n",
    "def build_lstm(input_shape):\n",
    "    reg = regularizers.l2(1e-4)\n",
    "    inp = layers.Input(shape=input_shape)  # (T,51)\n",
    "    x = layers.Masking(mask_value=0.0)(inp)\n",
    "    x = layers.LSTM(64, return_sequences=True, dropout=0.3)(x)\n",
    "    x = layers.SpatialDropout1D(0.1)(x)\n",
    "    x = layers.LSTM(32, dropout=0.3)(x)\n",
    "    x = layers.Dense(64, activation=\"relu\", kernel_regularizer=reg)(x)\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return models.Model(inp, out)\n",
    "\n",
    "def _conv_block(x, filters, reg):\n",
    "    x = layers.Conv1D(filters, 3, padding=\"same\", use_bias=False, kernel_regularizer=reg)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def build_cnn_lstm(input_shape):\n",
    "    reg = regularizers.l2(1e-4)\n",
    "    inp = layers.Input(shape=input_shape)  # (T,51)\n",
    "    x = layers.Masking(mask_value=0.0)(inp)\n",
    "    x = _conv_block(x, 64, reg)\n",
    "    x = _conv_block(x, 64, reg)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.SpatialDropout1D(0.1)(x)\n",
    "    x = layers.LSTM(64, return_sequences=True, dropout=0.3)(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.LSTM(32, dropout=0.3)(x)\n",
    "    x = layers.Dense(64, activation=\"relu\", kernel_regularizer=reg)(x)\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return models.Model(inp, out)\n",
    "\n",
    "# =======================\n",
    "# MAIN\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Cargar .npz y construir ventanas\n",
    "    paths = []\n",
    "    for d in NPZ_DIRS:\n",
    "        paths += sorted(Path(d).glob(\"*.npz\"))\n",
    "    assert paths, \"No se encontraron .npz en NPZ_DIRS\"\n",
    "\n",
    "    X_list, y_list, vid_ids, dom_list = [], [], [], []\n",
    "    for p in paths:\n",
    "        Xw, Yw, vid, dom = video_to_windows(p)\n",
    "        if len(Xw):\n",
    "            X_list.append(Xw); y_list.append(Yw)\n",
    "            vid_ids += [vid] * len(Yw)\n",
    "            dom_list += [dom] * len(Yw)\n",
    "\n",
    "    if not X_list:\n",
    "        raise RuntimeError(\"No se generaron ventanas (sube MIN_VIS_FRAC o revisa datos).\")\n",
    "\n",
    "    X_all = np.concatenate(X_list, 0).astype(\"float32\")  # (N,T,51)\n",
    "    y_all = np.concatenate(y_list, 0).astype(\"int32\")    # (N,)\n",
    "    print(f\"Total ventanas: {len(y_all)} | Pos={y_all.sum()} ({y_all.mean():.3f})\")\n",
    "\n",
    "    # 2) Split por VIDEO estratificado por dominio\n",
    "    vids_arr = np.array(vid_ids)\n",
    "    doms_arr = np.array(dom_list)\n",
    "    train_ids, val_ids, test_ids = stratified_split_by_domain(vids_arr, doms_arr, VAL_RATIO, TEST_RATIO, seed=SEED)\n",
    "\n",
    "    tr_mask = np.isin(vids_arr, list(train_ids))\n",
    "    va_mask = np.isin(vids_arr, list(val_ids))\n",
    "    te_mask = np.isin(vids_arr, list(test_ids))\n",
    "\n",
    "    X_tr, y_tr = X_all[tr_mask], y_all[tr_mask]\n",
    "    X_va, y_va = X_all[va_mask], y_all[va_mask]\n",
    "    X_te, y_te = X_all[te_mask], y_all[te_mask]\n",
    "\n",
    "    print(f\"Splits → train={len(y_tr)}  val={len(y_va)}  test={len(y_te)}\")\n",
    "\n",
    "    X_tr, X_va, X_te, stats = standardize_fit_apply(X_tr, X_va, X_te)\n",
    "\n",
    "    # noise = np.random.normal(0, 0.01, size=X_tr.shape).astype(\"float32\")\n",
    "    # X_tr = np.clip(X_tr + noise, -3.0, 3.0)\n",
    "\n",
    "    input_shape = (X_tr.shape[1], X_tr.shape[2])  # (SEQ_LEN, 51)\n",
    "    model = build_lstm(input_shape) if MODEL_KIND == \"lstm\" else build_cnn_lstm(input_shape)\n",
    "    model_name = f\"mix_{MODEL_KIND}_T{SEQ_LEN}_F{input_shape[1]}\"\n",
    "    model.summary()\n",
    "\n",
    "    try:\n",
    "        AdamW = tf.keras.optimizers.AdamW\n",
    "    except AttributeError:\n",
    "        from tensorflow.keras.optimizers.experimental import AdamW\n",
    "    opt = AdamW(learning_rate=3e-4, weight_decay=1e-4)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=BinaryFocalCrossentropy(gamma=1.5, label_smoothing=0.02),\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(name=\"acc\"),\n",
    "            tf.keras.metrics.AUC(name=\"auc\"),\n",
    "            tf.keras.metrics.AUC(name=\"pr_auc\", curve=\"PR\"),\n",
    "            tf.keras.metrics.Precision(name=\"precision\"),\n",
    "            tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    cbs = [\n",
    "        callbacks.ModelCheckpoint(str(MODEL_DIR / f\"{model_name}.keras\"),\n",
    "                                  save_best_only=True, monitor=\"val_pr_auc\", mode=\"max\"),\n",
    "        callbacks.ReduceLROnPlateau(monitor=\"val_pr_auc\", mode=\"max\",\n",
    "                                    factor=0.5, patience=4, verbose=1),\n",
    "        callbacks.EarlyStopping(monitor=\"val_pr_auc\", mode=\"max\",\n",
    "                                patience=8, restore_best_weights=True, verbose=1),\n",
    "    ]\n",
    "\n",
    "    hist = model.fit(\n",
    "        X_tr, y_tr,\n",
    "        validation_data=(X_va, y_va),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_weight=None,   # focal+AdamW\n",
    "        callbacks=cbs,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    y_val_prob = model.predict(X_va, batch_size=BATCH_SIZE, verbose=0).ravel()\n",
    "    ts = np.linspace(0.05, 0.95, 19)\n",
    "    best_f1, best_t = -1.0, 0.5\n",
    "    for t in ts:\n",
    "        y_pred = (y_val_prob >= t).astype(int)\n",
    "        f1 = f1_score(y_va, y_pred, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, float(t)\n",
    "    print(f\"\\nMejor umbral (val, F1): t={best_t:.2f}  F1={best_f1:.3f}\")\n",
    "\n",
    "    y_te_prob = model.predict(X_te, batch_size=BATCH_SIZE, verbose=0).ravel()\n",
    "    y_te_pred = (y_te_prob >= best_t).astype(int)\n",
    "\n",
    "    print(\"\\n=== TEST ===\")\n",
    "    print(\"ROC-AUC :\", roc_auc_score(y_te, y_te_prob))\n",
    "    print(\"PR-AUC  :\", average_precision_score(y_te, y_te_prob))\n",
    "    print(classification_report(y_te, y_te_pred, digits=4))\n",
    "    print(confusion_matrix(y_te, y_te_pred))\n",
    "\n",
    "    np.savez(MODEL_DIR / f\"{model_name}_norm_stats.npz\", mean=stats[\"mean\"], std=stats[\"std\"])\n",
    "    with open(MODEL_DIR / f\"{model_name}_threshold.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"best_threshold\": best_t}, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"\\nGuardado modelo: {MODEL_DIR / f'{model_name}.keras'}\")\n",
    "    print(f\"Guardado norm stats: {MODEL_DIR / f'{model_name}_norm_stats.npz'}\")\n",
    "    print(f\"Guardado umbral óptimo: {MODEL_DIR / f'{model_name}_threshold.json'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4ae1600e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Carpeta: C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\out_npz ===\n",
      "1_003_0.npz                  | frames=  6299  pos=     0  neg=  6299  pos_ratio=0.0000\n",
      "1_033_0.npz                  | frames=  1799  pos=     0  neg=  1799  pos_ratio=0.0000\n",
      "1_069_1.npz                  | frames=  1199  pos=   877  neg=   322  pos_ratio=0.7314\n",
      "1_070_1.npz                  | frames=   449  pos=   198  neg=   251  pos_ratio=0.4410\n",
      "1_071_1.npz                  | frames=   599  pos=   322  neg=   277  pos_ratio=0.5376\n",
      "1_073_1.npz                  | frames=   449  pos=   150  neg=   299  pos_ratio=0.3341\n",
      "1_076_1.npz                  | frames=   449  pos=   121  neg=   328  pos_ratio=0.2695\n",
      "1_078_1.npz                  | frames=  1199  pos=   651  neg=   548  pos_ratio=0.5430\n",
      "1_082_1.npz                  | frames=   449  pos=   159  neg=   290  pos_ratio=0.3541\n",
      "1_083_1.npz                  | frames=   449  pos=   212  neg=   237  pos_ratio=0.4722\n",
      "1_084_1.npz                  | frames=  1199  pos=   839  neg=   360  pos_ratio=0.6997\n",
      "1_088_1.npz                  | frames=  1349  pos=   812  neg=   537  pos_ratio=0.6019\n",
      "1_091_1.npz                  | frames=  1349  pos=  1086  neg=   263  pos_ratio=0.8050\n",
      "2_047_0.npz                  | frames=  2700  pos=     0  neg=  2700  pos_ratio=0.0000\n",
      "2_051_0.npz                  | frames=  1950  pos=     0  neg=  1950  pos_ratio=0.0000\n",
      "2_052_0.npz                  | frames=  2790  pos=     0  neg=  2790  pos_ratio=0.0000\n",
      "2_053_0.npz                  | frames=   750  pos=     0  neg=   750  pos_ratio=0.0000\n",
      "2_054_0.npz                  | frames=  1200  pos=     0  neg=  1200  pos_ratio=0.0000\n",
      "2_055_0.npz                  | frames=  1350  pos=     0  neg=  1350  pos_ratio=0.0000\n",
      "2_067_1.npz                  | frames=   750  pos=   146  neg=   604  pos_ratio=0.1947\n",
      "2_069_1.npz                  | frames=   750  pos=   393  neg=   357  pos_ratio=0.5240\n",
      "2_070_1.npz                  | frames=   600  pos=   119  neg=   481  pos_ratio=0.1983\n",
      "2_075_1.npz                  | frames=   450  pos=   159  neg=   291  pos_ratio=0.3533\n",
      "2_076_1.npz                  | frames=   750  pos=   318  neg=   432  pos_ratio=0.4240\n",
      "2_077_1.npz                  | frames=   360  pos=   171  neg=   189  pos_ratio=0.4750\n",
      "2_078_1.npz                  | frames=   450  pos=   153  neg=   297  pos_ratio=0.3400\n",
      "2_079_1.npz                  | frames=   600  pos=   361  neg=   239  pos_ratio=0.6017\n",
      "2_080_1.npz                  | frames=  1800  pos=  1060  neg=   740  pos_ratio=0.5889\n",
      "2_081_1.npz                  | frames=   510  pos=   426  neg=    84  pos_ratio=0.8353\n",
      "2_082_1.npz                  | frames=  1350  pos=   156  neg=  1194  pos_ratio=0.1156\n",
      "2_083_1.npz                  | frames=  2850  pos=  1183  neg=  1667  pos_ratio=0.4151\n",
      "2_084_1.npz                  | frames=   600  pos=   325  neg=   275  pos_ratio=0.5417\n",
      "2_085_1.npz                  | frames=   300  pos=    88  neg=   212  pos_ratio=0.2933\n",
      "2_086_1.npz                  | frames=  1500  pos=   901  neg=   599  pos_ratio=0.6007\n",
      "2_087_1.npz                  | frames=   750  pos=   251  neg=   499  pos_ratio=0.3347\n",
      "2_088_1.npz                  | frames=   660  pos=   250  neg=   410  pos_ratio=0.3788\n",
      "2_089_1.npz                  | frames=  1050  pos=   557  neg=   493  pos_ratio=0.5305\n",
      "2_090_1.npz                  | frames=  5400  pos=  2634  neg=  2766  pos_ratio=0.4878\n",
      "2_091_0.npz                  | frames=  2400  pos=     0  neg=  2400  pos_ratio=0.0000\n",
      "2_092_1.npz                  | frames=   450  pos=    51  neg=   399  pos_ratio=0.1133\n",
      "2_093_1.npz                  | frames=  1950  pos=  1306  neg=   644  pos_ratio=0.6697\n",
      "2_094_1.npz                  | frames=  3600  pos=   173  neg=  3427  pos_ratio=0.0481\n",
      "2_095_1.npz                  | frames=   450  pos=   232  neg=   218  pos_ratio=0.5156\n",
      "2_096_1.npz                  | frames=   450  pos=   198  neg=   252  pos_ratio=0.4400\n",
      "3_028_0.npz                  | frames=  5398  pos=     0  neg=  5398  pos_ratio=0.0000\n",
      "3_032_0.npz                  | frames=  1649  pos=     0  neg=  1649  pos_ratio=0.0000\n",
      "3_033_0.npz                  | frames=  2999  pos=     0  neg=  2999  pos_ratio=0.0000\n",
      "3_034_0.npz                  | frames=  2699  pos=     0  neg=  2699  pos_ratio=0.0000\n",
      "3_035_0.npz                  | frames=  1353  pos=     0  neg=  1353  pos_ratio=0.0000\n",
      "3_057_0.npz                  | frames=  3299  pos=     0  neg=  3299  pos_ratio=0.0000\n",
      "3_074_0.npz                  | frames=  1010  pos=     0  neg=  1010  pos_ratio=0.0000\n",
      "3_074_1.npz                  | frames=   599  pos=    41  neg=   558  pos_ratio=0.0684\n",
      "3_075_1.npz                  | frames=   906  pos=   185  neg=   721  pos_ratio=0.2042\n",
      "3_076_1.npz                  | frames=  1492  pos=   876  neg=   616  pos_ratio=0.5871\n",
      "3_077_1.npz                  | frames=   899  pos=   355  neg=   544  pos_ratio=0.3949\n",
      "3_078_1.npz                  | frames=  1499  pos=   255  neg=  1244  pos_ratio=0.1701\n",
      "3_079_1.npz                  | frames=  1349  pos=   538  neg=   811  pos_ratio=0.3988\n",
      "3_080_1.npz                  | frames=   899  pos=   238  neg=   661  pos_ratio=0.2647\n",
      "3_081_1.npz                  | frames=   890  pos=   192  neg=   698  pos_ratio=0.2157\n",
      "3_082_1.npz                  | frames=   899  pos=   126  neg=   773  pos_ratio=0.1402\n",
      "3_083_1.npz                  | frames=   599  pos=   158  neg=   441  pos_ratio=0.2638\n",
      "3_084_1.npz                  | frames=   731  pos=   161  neg=   570  pos_ratio=0.2202\n",
      "3_085_1.npz                  | frames=   599  pos=   127  neg=   472  pos_ratio=0.2120\n",
      "3_086_1.npz                  | frames=  2699  pos=   701  neg=  1998  pos_ratio=0.2597\n",
      "3_087_1.npz                  | frames=   599  pos=   184  neg=   415  pos_ratio=0.3072\n",
      "3_088_1.npz                  | frames=   599  pos=    75  neg=   524  pos_ratio=0.1252\n",
      "3_089_1.npz                  | frames=   899  pos=   581  neg=   318  pos_ratio=0.6463\n",
      "3_090_1.npz                  | frames=   599  pos=   147  neg=   452  pos_ratio=0.2454\n",
      "3_091_1.npz                  | frames=   599  pos=   166  neg=   433  pos_ratio=0.2771\n",
      "3_092_1.npz                  | frames=  2099  pos=   960  neg=  1139  pos_ratio=0.4574\n",
      "3_093_1.npz                  | frames=  1049  pos=   336  neg=   713  pos_ratio=0.3203\n",
      "3_094_1.npz                  | frames=   749  pos=   192  neg=   557  pos_ratio=0.2563\n",
      "3_095_1.npz                  | frames=   749  pos=   344  neg=   405  pos_ratio=0.4593\n",
      "3_096_1.npz                  | frames=   449  pos=   191  neg=   258  pos_ratio=0.4254\n",
      "3_097_1.npz                  | frames=   749  pos=   226  neg=   523  pos_ratio=0.3017\n",
      "3_098_1.npz                  | frames=  1499  pos=   478  neg=  1021  pos_ratio=0.3189\n",
      "3_099_1.npz                  | frames=  1649  pos=  1301  neg=   348  pos_ratio=0.7890\n",
      "3_100_1.npz                  | frames=   599  pos=   381  neg=   218  pos_ratio=0.6361\n",
      "3_102_1.npz                  | frames=  2399  pos=  1312  neg=  1087  pos_ratio=0.5469\n",
      "3_103_1.npz                  | frames=   449  pos=   128  neg=   321  pos_ratio=0.2851\n",
      "3_104_1.npz                  | frames=   749  pos=   338  neg=   411  pos_ratio=0.4513\n",
      "3_105_1.npz                  | frames=   601  pos=   265  neg=   336  pos_ratio=0.4409\n",
      "3_106_1.npz                  | frames=   449  pos=   255  neg=   194  pos_ratio=0.5679\n",
      "4_003_0.npz                  | frames=  1709  pos=     0  neg=  1709  pos_ratio=0.0000\n",
      "4_004_0.npz                  | frames=  1829  pos=     0  neg=  1829  pos_ratio=0.0000\n",
      "4_005_0.npz                  | frames=  5849  pos=     0  neg=  5849  pos_ratio=0.0000\n",
      "4_007_0.npz                  | frames=  3455  pos=     0  neg=  3455  pos_ratio=0.0000\n",
      "4_039_0.npz                  | frames=  2549  pos=     0  neg=  2549  pos_ratio=0.0000\n",
      "4_040_0.npz                  | frames=  1949  pos=     0  neg=  1949  pos_ratio=0.0000\n",
      "4_062_0.npz                  | frames=  4079  pos=     0  neg=  4079  pos_ratio=0.0000\n",
      "4_063_0.npz                  | frames=  3449  pos=     0  neg=  3449  pos_ratio=0.0000\n",
      "4_073_0.npz                  | frames=  5399  pos=     0  neg=  5399  pos_ratio=0.0000\n",
      "4_074_0.npz                  | frames=   398  pos=     0  neg=   398  pos_ratio=0.0000\n",
      "4_075_0.npz                  | frames=   149  pos=     0  neg=   149  pos_ratio=0.0000\n",
      "4_076_1.npz                  | frames=   419  pos=   238  neg=   181  pos_ratio=0.5680\n",
      "4_077_1.npz                  | frames=   329  pos=   216  neg=   113  pos_ratio=0.6565\n",
      "4_078_1.npz                  | frames=   299  pos=   136  neg=   163  pos_ratio=0.4548\n",
      "4_080_1.npz                  | frames=   659  pos=   371  neg=   288  pos_ratio=0.5630\n",
      "4_081_1.npz                  | frames=   599  pos=   264  neg=   335  pos_ratio=0.4407\n",
      "4_082_1.npz                  | frames=   929  pos=   769  neg=   160  pos_ratio=0.8278\n",
      "4_083_1.npz                  | frames=   599  pos=   378  neg=   221  pos_ratio=0.6311\n",
      "4_084_1.npz                  | frames=   449  pos=   159  neg=   290  pos_ratio=0.3541\n",
      "4_085_1.npz                  | frames=   419  pos=   107  neg=   312  pos_ratio=0.2554\n",
      "4_086_1.npz                  | frames=   479  pos=   224  neg=   255  pos_ratio=0.4676\n",
      "4_087_1.npz                  | frames=   479  pos=   262  neg=   217  pos_ratio=0.5470\n",
      "4_088_1.npz                  | frames=   419  pos=   151  neg=   268  pos_ratio=0.3604\n",
      "4_089_1.npz                  | frames=  2249  pos=   743  neg=  1506  pos_ratio=0.3304\n",
      "4_090_1.npz                  | frames=   299  pos=   138  neg=   161  pos_ratio=0.4615\n",
      "4_092_1.npz                  | frames=   299  pos=   173  neg=   126  pos_ratio=0.5786\n",
      "4_100_1.npz                  | frames=   269  pos=   141  neg=   128  pos_ratio=0.5242\n",
      "4_101_1.npz                  | frames=   719  pos=   381  neg=   338  pos_ratio=0.5299\n",
      "4_107_1.npz                  | frames=   749  pos=   221  neg=   528  pos_ratio=0.2951\n",
      "4_108_1.npz                  | frames=   359  pos=   167  neg=   192  pos_ratio=0.4652\n",
      "-- Subtotal out_npz: frames=150592  pos=34090  neg=116502  pos_ratio=0.2264\n",
      "\n",
      "=== Carpeta: C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\out_npz_fall ===\n",
      "video (1).npz                | frames=   157  pos=    33  neg=   124  pos_ratio=0.2102\n",
      "video (10).npz               | frames=   362  pos=    28  neg=   334  pos_ratio=0.0773\n",
      "video (11).npz               | frames=   483  pos=    30  neg=   453  pos_ratio=0.0621\n",
      "video (12).npz               | frames=   182  pos=    23  neg=   159  pos_ratio=0.1264\n",
      "video (13).npz               | frames=   244  pos=    20  neg=   224  pos_ratio=0.0820\n",
      "video (14).npz               | frames=   176  pos=    25  neg=   151  pos_ratio=0.1420\n",
      "video (2).npz                | frames=   306  pos=    28  neg=   278  pos_ratio=0.0915\n",
      "video (3).npz                | frames=   304  pos=    39  neg=   265  pos_ratio=0.1283\n",
      "video (4).npz                | frames=   207  pos=    33  neg=   174  pos_ratio=0.1594\n",
      "video (5).npz                | frames=   181  pos=    33  neg=   148  pos_ratio=0.1823\n",
      "video (6).npz                | frames=   239  pos=    30  neg=   209  pos_ratio=0.1255\n",
      "video (7).npz                | frames=   174  pos=    31  neg=   143  pos_ratio=0.1782\n",
      "video (8).npz                | frames=   258  pos=    26  neg=   232  pos_ratio=0.1008\n",
      "video (9).npz                | frames=   206  pos=    33  neg=   173  pos_ratio=0.1602\n",
      "-- Subtotal out_npz_fall: frames=3479  pos=412  neg=3067  pos_ratio=0.1184\n",
      "\n",
      "=== Carpeta: C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\out_npz_video ===\n",
      "2.npz                        | frames=   132  pos=   122  neg=    10  pos_ratio=0.9242\n",
      "3.npz                        | frames=    93  pos=    83  neg=    10  pos_ratio=0.8925\n",
      "n015_converted.npz           | frames=   133  pos=     0  neg=   133  pos_ratio=0.0000\n",
      "n142_converted.npz           | frames=   147  pos=     0  neg=   147  pos_ratio=0.0000\n",
      "n154_converted.npz           | frames=    31  pos=     0  neg=    31  pos_ratio=0.0000\n",
      "n155_converted.npz           | frames=    31  pos=     0  neg=    31  pos_ratio=0.0000\n",
      "n156_converted.npz           | frames=   132  pos=     0  neg=   132  pos_ratio=0.0000\n",
      "n157_converted.npz           | frames=   119  pos=     0  neg=   119  pos_ratio=0.0000\n",
      "n190_converted.npz           | frames=   125  pos=     0  neg=   125  pos_ratio=0.0000\n",
      "n191_converted.npz           | frames=   126  pos=     0  neg=   126  pos_ratio=0.0000\n",
      "Normal_Videos_100_x264.npz   | frames=   627  pos=     0  neg=   627  pos_ratio=0.0000\n",
      "Normal_Videos_129_x264.npz   | frames=   467  pos=     0  neg=   467  pos_ratio=0.0000\n",
      "Normal_Videos_345_x264.npz   | frames=   209  pos=     0  neg=   209  pos_ratio=0.0000\n",
      "Normal_Videos_360_x264.npz   | frames=   984  pos=     0  neg=   984  pos_ratio=0.0000\n",
      "NV_1.npz                     | frames=    66  pos=     0  neg=    66  pos_ratio=0.0000\n",
      "Robbery070_x264.npz          | frames=   591  pos=   581  neg=    10  pos_ratio=0.9831\n",
      "t_n008_converted.npz         | frames=   119  pos=     0  neg=   119  pos_ratio=0.0000\n",
      "t_n009_converted.npz         | frames=   129  pos=     0  neg=   129  pos_ratio=0.0000\n",
      "t_n010_converted.npz         | frames=   138  pos=     0  neg=   138  pos_ratio=0.0000\n",
      "t_n012_converted.npz         | frames=   131  pos=     0  neg=   131  pos_ratio=0.0000\n",
      "t_n013_converted.npz         | frames=   139  pos=     0  neg=   139  pos_ratio=0.0000\n",
      "t_n014_converted.npz         | frames=   124  pos=     0  neg=   124  pos_ratio=0.0000\n",
      "t_n015_converted.npz         | frames=   134  pos=     0  neg=   134  pos_ratio=0.0000\n",
      "t_n016_converted.npz         | frames=    76  pos=     0  neg=    76  pos_ratio=0.0000\n",
      "v025_converted.npz           | frames=   311  pos=   301  neg=    10  pos_ratio=0.9678\n",
      "v068_converted.npz           | frames=   327  pos=   317  neg=    10  pos_ratio=0.9694\n",
      "v075_converted.npz           | frames=   324  pos=   314  neg=    10  pos_ratio=0.9691\n",
      "v081_converted.npz           | frames=   321  pos=   311  neg=    10  pos_ratio=0.9688\n",
      "V_1.npz                      | frames=   103  pos=    93  neg=    10  pos_ratio=0.9029\n",
      "V_21.npz                     | frames=   180  pos=   170  neg=    10  pos_ratio=0.9444\n",
      "V_23.npz                     | frames=   126  pos=   116  neg=    10  pos_ratio=0.9206\n",
      "V_26.npz                     | frames=   126  pos=   116  neg=    10  pos_ratio=0.9206\n",
      "V_290.npz                    | frames=   141  pos=   131  neg=    10  pos_ratio=0.9291\n",
      "V_297.npz                    | frames=   141  pos=   131  neg=    10  pos_ratio=0.9291\n",
      "V_3.npz                      | frames=   174  pos=   164  neg=    10  pos_ratio=0.9425\n",
      "V_300.npz                    | frames=   195  pos=   185  neg=    10  pos_ratio=0.9487\n",
      "V_320.npz                    | frames=   162  pos=   152  neg=    10  pos_ratio=0.9383\n",
      "V_321.npz                    | frames=   132  pos=   122  neg=    10  pos_ratio=0.9242\n",
      "V_4.npz                      | frames=   151  pos=   141  neg=    10  pos_ratio=0.9338\n",
      "V_413.npz                    | frames=   117  pos=   107  neg=    10  pos_ratio=0.9145\n",
      "V_421.npz                    | frames=   159  pos=   149  neg=    10  pos_ratio=0.9371\n",
      "V_452.npz                    | frames=   141  pos=   131  neg=    10  pos_ratio=0.9291\n",
      "V_5.npz                      | frames=   114  pos=   104  neg=    10  pos_ratio=0.9123\n",
      "V_58.npz                     | frames=   117  pos=   107  neg=    10  pos_ratio=0.9145\n",
      "V_62.npz                     | frames=   114  pos=   104  neg=    10  pos_ratio=0.9123\n",
      "V_629.npz                    | frames=   180  pos=   170  neg=    10  pos_ratio=0.9444\n",
      "V_63.npz                     | frames=   129  pos=   119  neg=    10  pos_ratio=0.9225\n",
      "V_630.npz                    | frames=   150  pos=   140  neg=    10  pos_ratio=0.9333\n",
      "V_638.npz                    | frames=   150  pos=   140  neg=    10  pos_ratio=0.9333\n",
      "V_70.npz                     | frames=   147  pos=   137  neg=    10  pos_ratio=0.9320\n",
      "V_71.npz                     | frames=   150  pos=   140  neg=    10  pos_ratio=0.9333\n",
      "V_72.npz                     | frames=   150  pos=   140  neg=    10  pos_ratio=0.9333\n",
      "V_743.npz                    | frames=   141  pos=   131  neg=    10  pos_ratio=0.9291\n",
      "V_75.npz                     | frames=   150  pos=   140  neg=    10  pos_ratio=0.9333\n",
      "V_752.npz                    | frames=   126  pos=   116  neg=    10  pos_ratio=0.9206\n",
      "V_755.npz                    | frames=   126  pos=   116  neg=    10  pos_ratio=0.9206\n",
      "V_761.npz                    | frames=   126  pos=   116  neg=    10  pos_ratio=0.9206\n",
      "V_764.npz                    | frames=   123  pos=   113  neg=    10  pos_ratio=0.9187\n",
      "V_765.npz                    | frames=   129  pos=   119  neg=    10  pos_ratio=0.9225\n",
      "V_84.npz                     | frames=   150  pos=   140  neg=    10  pos_ratio=0.9333\n",
      "V_85.npz                     | frames=   150  pos=   140  neg=    10  pos_ratio=0.9333\n",
      "V_86.npz                     | frames=   150  pos=   140  neg=    10  pos_ratio=0.9333\n",
      "V_957.npz                    | frames=   159  pos=   149  neg=    10  pos_ratio=0.9371\n",
      "Vídeo sin título ‐ Hecho con Clipchamp.npz | frames=   138  pos=   128  neg=    10  pos_ratio=0.9275\n",
      "-- Subtotal out_npz_video: frames=11403  pos=6786  neg=4617  pos_ratio=0.5951\n",
      "\n",
      "=== TOTAL GLOBAL ===\n",
      "frames=165474  pos=41288  neg=124186  pos_ratio=0.2495\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIG: agrega/quita carpetas con tus .npz ===\n",
    "NPZ_DIRS   = [\n",
    "    r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\out_npz\",          # CHAD\n",
    "    r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\out_npz_fall\",     # FALL\n",
    "    r\"C:\\Users\\Usuario\\Documents\\GitHub\\tesis-deteccionar-sistema\\out_npz_video\"\n",
    "]\n",
    "\n",
    "TH = 0.5  # umbral para considerar positivo si las etiquetas vienen como float\n",
    "\n",
    "def count_labels_in_file(npz_path: Path, th=TH):\n",
    "    z = np.load(npz_path, allow_pickle=True)\n",
    "    if \"labels_aligned\" not in z.files:\n",
    "        return 0, 0, 0\n",
    "    y = z[\"labels_aligned\"]\n",
    "    # soporta float/bool/int; convierte a 0/1 con umbral si hace falta\n",
    "    if y.dtype.kind in \"fc\":\n",
    "        y_bin = (y >= th).astype(np.int64)\n",
    "    else:\n",
    "        y_bin = y.astype(np.int64)\n",
    "    pos = int(y_bin.sum())\n",
    "    tot = int(y_bin.shape[0])\n",
    "    neg = tot - pos\n",
    "    return pos, neg, tot\n",
    "\n",
    "def main():\n",
    "    grand_pos = grand_neg = grand_tot = 0\n",
    "    for d in NPZ_DIRS:\n",
    "        d = Path(d)\n",
    "        npzs = sorted(d.glob(\"*.npz\"))\n",
    "        if not npzs:\n",
    "            print(f\"[{d}] sin archivos .npz\")\n",
    "            continue\n",
    "\n",
    "        dir_pos = dir_neg = dir_tot = 0\n",
    "        print(f\"\\n=== Carpeta: {d} ===\")\n",
    "        for p in npzs:\n",
    "            pos, neg, tot = count_labels_in_file(p)\n",
    "            dir_pos += pos; dir_neg += neg; dir_tot += tot\n",
    "            print(f\"{p.name:<28} | frames={tot:6d}  pos={pos:6d}  neg={neg:6d}  pos_ratio={pos/ tot if tot else 0:.4f}\")\n",
    "\n",
    "        grand_pos += dir_pos; grand_neg += dir_neg; grand_tot += dir_tot\n",
    "        print(f\"-- Subtotal {d.name}: frames={dir_tot}  pos={dir_pos}  neg={dir_neg}  pos_ratio={(dir_pos/dir_tot if dir_tot else 0):.4f}\")\n",
    "\n",
    "    print(\"\\n=== TOTAL GLOBAL ===\")\n",
    "    print(f\"frames={grand_tot}  pos={grand_pos}  neg={grand_neg}  pos_ratio={(grand_pos/grand_tot if grand_tot else 0):.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
